{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":112899,"databundleVersionId":13449579,"sourceType":"competition"}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torchvision import models, transforms\nfrom torchmetrics.functional import accuracy, recall, precision, auroc\nfrom torch.utils.data import Dataset, DataLoader\nimport timm\nimport numpy as np\nimport pandas as pd\nimport random\nfrom typing import List\nfrom tqdm import tqdm\nfrom torchmetrics.functional import accuracy, recall, precision, auroc\nfrom PIL import Image, ImageEnhance, ImageOps, ImageFilter\nimport os\nfrom glob import glob\nfrom sklearn.model_selection import train_test_split\n\nBASE_DIR = \"/kaggle/input/grand-xray-slam-division-a\"\nlabel_columns = [\n    'Atelectasis', 'Cardiomegaly', 'Consolidation', 'Edema', 'Enlarged Cardiomediastinum',\n    'Fracture', 'Lung Lesion', 'Lung Opacity', 'No Finding', 'Pleural Effusion',\n    'Pleural Other', 'Pneumonia', 'Pneumothorax', 'Support Devices'\n]\n\n\ndef setup_seed(seed=None):\n    if seed is None:\n        return\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    np.random.seed(seed)\n    random.seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T17:24:58.800316Z","iopub.execute_input":"2025-09-18T17:24:58.800533Z","iopub.status.idle":"2025-09-18T17:25:14.893058Z","shell.execute_reply.started":"2025-09-18T17:24:58.800515Z","shell.execute_reply":"2025-09-18T17:25:14.892465Z"}},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"### Augmentation Spaces and Utilities","metadata":{}},{"cell_type":"code","source":"# used to freeze layers in a model\ndef freeze_all(model):\n    for param in model.parameters():\n        param.requires_grad=False\n\ndef get_resnet18(num_classes=14, fine_tune=True):\n    model = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n\n    if fine_tune:\n        freeze_all(model)\n        for param in model.layer4.parameters():\n            param.requires_grad = True\n\n    model.fc = nn.Linear(512, num_classes)\n    return model\n\ndef get_resnet34(num_classes=14, fine_tune=True):\n    model = models.resnet34(weights=models.ResNet34_Weights.IMAGENET1K_V1)\n\n    if fine_tune:\n        freeze_all(model)\n        for param in model.layer4.parameters():\n            param.requires_grad = True\n\n    model.fc = nn.Linear(512, num_classes)\n    return model\n\ndef get_effnetb0(num_classes=14, fine_tune=True):\n    model = models.efficientnet_b0(weights=models.EfficientNet_B0_Weights.IMAGENET1K_V1)\n\n    if fine_tune:\n        freeze_all(model)\n        for idx in range(6, 8):\n            for param in model.features[idx].parameters():\n                param.requires_grad = True\n\n    model.classifier = nn.Sequential(\n        nn.Dropout(p=0.2, inplace=True),\n        nn.Linear(in_features=1280, out_features=num_classes)\n    )\n    \n    return model\n\ndef get_convnext_tiny(num_classes=14, fine_tune=True):\n    model = models.convnext_tiny(weights=models.ConvNeXt_Tiny_Weights.IMAGENET1K_V1)\n\n    if fine_tune:\n        freeze_all(model)\n        for param in model.features[6].parameters():\n            param.requires_grad = True\n\n    model.classifier[2] = nn.Linear(in_features=768, out_features=num_classes)\n    return model\n\n# returns getter function and number of in features of the classifier\nmodels_ = {\n    \"res18\": (get_resnet18, 512),\n    \"res34\": (get_resnet34, 512),\n    \"effb0\": (get_effnetb0, 1280),\n    \"convnext\" : (get_convnext_tiny, 768),\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T17:25:14.894306Z","iopub.execute_input":"2025-09-18T17:25:14.894797Z","iopub.status.idle":"2025-09-18T17:25:14.902905Z","shell.execute_reply.started":"2025-09-18T17:25:14.894777Z","shell.execute_reply":"2025-09-18T17:25:14.902200Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# Set up transforms\nbasic_transforms = transforms.Compose([\n    transforms.Resize((224, 224)), # resize to 224x224\n    transforms.ToTensor(), # convert to tensor [0,1]\n    transforms.Normalize( # normalize with ImageNet stats\n        mean=[0.485, 0.456, 0.406],\n        std=[0.229, 0.224, 0.225]\n    )\n])\n\n# custom transforms with adaptive magnitude\ndef shear_x(img, magnitude):\n    level = magnitude * 0.3 * random.choice([-1, 1])\n    return img.transform(img.size, Image.AFFINE, (1, level, 0, 0, 1, 0))\n\ndef shear_y(img, magnitude):\n    level = magnitude * 0.3 * random.choice([-1, 1])\n    return img.transform(img.size, Image.AFFINE, (1, 0, 0, level, 1, 0))\n\ndef translate_x(img, magnitude):\n    max_shift = 0.3 * img.size[0]\n    level = magnitude * max_shift * random.choice([-1, 1])\n    return img.transform(img.size, Image.AFFINE, (1, 0, level, 0, 1, 0))\n\ndef translate_y(img, magnitude):\n    max_shift = 0.3 * img.size[1]\n    level = magnitude * max_shift * random.choice([-1, 1])\n    return img.transform(img.size, Image.AFFINE, (1, 0, 0, 0, 1, level))\n\ndef rotate(img, magnitude):\n    degrees = magnitude * 30 * random.choice([-1, 1])\n    return img.rotate(degrees)\n\ndef contrast(img, magnitude):\n    enhancer = ImageEnhance.Contrast(img)\n    factor = 1.0 + (magnitude * random.choice([-0.9, 0.9]))\n    return enhancer.enhance(factor)\n\ndef brightness(img, magnitude):\n    enhancer = ImageEnhance.Brightness(img)\n    factor = 1.0 + (magnitude * random.choice([-0.9, 0.9]))\n    return enhancer.enhance(factor)\n\ndef sharpness(img, magnitude):\n    enhancer = ImageEnhance.Sharpness(img)\n    factor = 1.0 + (magnitude * random.choice([-0.9, 0.9]))\n    return enhancer.enhance(factor)\n\ndef equalize(img, magnitude=None):\n    return ImageOps.equalize(img)\n\ndef gaussian_blur(img, magnitude):\n    radius = magnitude * 2\n    return img.filter(ImageFilter.GaussianBlur(radius))\n\ndef identity(img, magnitude=None):\n    return img\n\naugmentation_space = [\n    shear_x, shear_y, \n    translate_x, translate_y,\n    rotate, equalize, \n    contrast, brightness, \n    sharpness, identity\n]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T17:25:14.903553Z","iopub.execute_input":"2025-09-18T17:25:14.903764Z","iopub.status.idle":"2025-09-18T17:25:14.925991Z","shell.execute_reply.started":"2025-09-18T17:25:14.903749Z","shell.execute_reply":"2025-09-18T17:25:14.925376Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# AdaAugment can be used to control augmentation magnitudes and operations\n\nclass AdaAugment:\n\n    def __init__(self, rand_m, rand_t):\n        self.key_transform = {}\n        self.key_magnitude = {}\n        self.transforms = augmentation_space\n        self.rand_m = rand_m\n        self.rand_t = rand_t\n\n    def set(self, keys, m, transform_idx=None):\n        for i, key in enumerate(keys):\n            self.key_magnitude[key] = m[i].cpu().detach()\n        \n        if transform_idx is not None:\n            for i, key in enumerate(keys):\n                self.key_transform[key] = transform_idx[i].cpu().detach()\n\n    def __call__(self, key, img):\n        # Get Magnitude for the sample\n        m = self.key_magnitude.get(key)\n        if m is None:  \n            if self.rand_m:\n                if random.random() < 0.4:\n                    return img  # skip transform\n                m = random.random() # select a random magnitude\n            else:\n                m = 0\n        else:\n            m = float(m)\n    \n        # Get transform\n        t = self.key_transform.get(key)\n        if t is None:\n            t = random.choice(self.transforms) if self.rand_t else self.transforms[-1] # if rand_t => select random augementation => else => use identiy as first transformation\n        else:\n            t = self.transforms[int(t)]\n\n        return t(img, m) # return applied transformation with corresponding magnitude\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T17:25:14.926520Z","iopub.execute_input":"2025-09-18T17:25:14.926761Z","iopub.status.idle":"2025-09-18T17:25:14.943121Z","shell.execute_reply.started":"2025-09-18T17:25:14.926735Z","shell.execute_reply":"2025-09-18T17:25:14.942518Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# Focal Loss for fine tuninng\n\nclass FocalLoss(nn.Module):\n\n    def __init__(self, weights:List=None, gamma=2.0, reduction=\"mean\"):\n        super().__init__()\n\n        self.weights = weights\n        self.gamma = gamma\n        self.reduction = reduction\n\n    def forward(self, logit, target):\n        bce_loss = nn.functional.binary_cross_entropy_with_logits(\n            logit, target,\n            reduction=\"none\"\n        )\n        probs = torch.exp(-bce_loss)\n        F_loss = self.weights.to(target.device) * (1-probs) ** self.gamma * bce_loss\n\n        if self.reduction == \"mean\":\n            return F_loss.mean()\n        elif self.reduction == \"none\":\n            return F_loss   \n        else:\n            return F_loss.sum()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T17:25:14.944644Z","iopub.execute_input":"2025-09-18T17:25:14.944947Z","iopub.status.idle":"2025-09-18T17:25:14.956696Z","shell.execute_reply.started":"2025-09-18T17:25:14.944923Z","shell.execute_reply":"2025-09-18T17:25:14.956026Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# Saves per sample information such as previous loss etc.\n\nclass ValueMemory:\n    def __init__(self):\n        \"\"\"\n        Stores the last value per key (no EMA).\n        \"\"\"\n        self.values = {}\n\n    def __call__(self, keys, vals):\n        \"\"\"\n        keys: list of sample identifiers\n        vals: torch.Tensor of shape (len(keys), D)\n        Returns: current stored values, previous stored values\n        \"\"\"\n        stored_list = []\n        new_list = []\n\n        for i, key in enumerate(keys):\n            val = vals[i]\n            if key not in self.values:\n                old = val.clone()  # nothing stored yet → use current\n            else:\n                old = self.values[key]\n\n            self.values[key] = val  # overwrite with last value\n\n            stored_list.append(old.unsqueeze(0))\n            new_list.append(self.values[key].unsqueeze(0))\n\n        stored = torch.cat(stored_list, dim=0)  # previous values\n        return stored\n\n    def get(self, key):\n        \"\"\"\n        Access the stored value for a single key\n        \"\"\"\n        return self.values.get(key, None)\n\n    def get_multi(self, keys):\n        \"\"\"\n        Access stored values for multiple keys\n        \"\"\"\n        return torch.stack([self.values[k] for k in keys])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T17:25:14.957350Z","iopub.execute_input":"2025-09-18T17:25:14.957615Z","iopub.status.idle":"2025-09-18T17:25:14.974353Z","shell.execute_reply.started":"2025-09-18T17:25:14.957592Z","shell.execute_reply":"2025-09-18T17:25:14.973630Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"### Setting up the AdaAugment Agent\n+ Critic => returns value for a state\n+ Actor => Parameterizes a beta distribution that is used to sample augmentation magnitudes\n+ Controller => Parameterizes a categorical distribution that is used to sample transformations from the augmentation space","metadata":{}},{"cell_type":"code","source":"class Actor(nn.Module):\n    def __init__(self, in_features, hidden, out_features):\n        super().__init__()\n        self.linear1 = nn.Linear(in_features, hidden)\n        self.layer_norm1 = nn.LayerNorm(hidden)\n        self.linear2 = nn.Linear(hidden, hidden)\n        self.alpha_head = nn.Linear(hidden, out_features)\n        self.beta_head = nn.Linear(hidden, out_features)\n\n    def forward(self, x):\n        x = torch.relu(self.linear1(self.layer_norm1(x)))\n        x = torch.relu(self.linear2(x))\n        return torch.softmax(self.alpha_head(x), dim=-1) + 1, torch.softmax(self.beta_head(x), dim=-1) + 1\n\n    def get_dist(self, x):\n        alpha, beta = self(x)\n        dist = torch.distributions.Beta(alpha, beta)\n        return dist\n\n\nclass Critic(nn.Module):\n\n    def __init__(self, in_features, hidden):\n        super().__init__()\n        self.linear1 = nn.Linear(in_features, hidden)\n        self.layer_norm1 = nn.LayerNorm(hidden)\n        self.linear2 = nn.Linear(hidden, hidden)\n        self.head = nn.Linear(hidden, 1)\n\n    def forward(self, x):\n        x = torch.relu(self.linear1(self.layer_norm1(x)))\n        x = torch.relu(self.linear2(x))\n        return self.head(x)\n\n\nclass Controller(nn.Module):\n\n    def __init__(self, in_features, hidden):\n        super().__init__()\n        self.linear1 = nn.Linear(in_features, hidden)\n        self.layer_norm1 = nn.LayerNorm(hidden)\n        self.linear2 = nn.Linear(hidden, hidden)\n        self.head = nn.Linear(hidden, len(augmentation_space))\n\n    def forward(self, x):\n        x = torch.relu(self.linear1(self.layer_norm1(x)))\n        x = torch.relu(self.linear2(x))\n        return self.head(x)\n    \n    def get_dist(self, x):\n        out = self(x)\n        dist = torch.distributions.Categorical(logits=out)\n        return dist\n\n\nclass Agent(nn.Module):\n\n    def __init__(self, in_features, control=False, actor=False):\n        super().__init__()\n        self.val_memory = ValueMemory()\n        self.loss_memory = ValueMemory()\n\n        self.critic = Critic(in_features=in_features, hidden=128)\n\n        self.store_ = {}\n\n        self.control_ = control\n        self.actor_ = actor\n        if control:\n            self.controller = Controller(in_features=in_features, hidden=128)\n\n        if actor:\n            self.actor = Actor(in_features=in_features, hidden=128, out_features=1) \n\n        self.actor_optimizer = torch.optim.Adam(\n            params=self.actor.parameters(), lr=3e-5, weight_decay=5e-4\n        )\n        self.critic_optimizer = torch.optim.Adam(\n            params=self.critic.parameters(), lr=3e-5, weight_decay=5e-4\n        )\n\n    def action(self, state):\n        action_actor = None\n        action_controller = None\n        if self.actor_:  \n            dist = self.actor.get_dist(state.detach())\n            action_actor = dist.sample()\n            self.store_[\"action_actor\"] = action_actor\n            self.store_[\"dist_actor\"] = dist\n        if self.control_:\n            dist = self.controller.get_dist(state.detach())\n            action_controller = dist.sample()\n            self.store_[\"action_controller\"] = action_controller\n            self.store_[\"dist_controller\"] = dist\n\n        return action_actor, action_controller\n\n    def update(self, key, state, reward):\n        value = self.critic(state)\n        prev_state = self.val_memory(key, state)\n        prev_value = self.critic(prev_state)\n        \n        with torch.no_grad():\n            td_target = reward + 0.99 * value\n\n        if self.actor_ and self.control_:\n            dist_actor, action_actor = self.store_[\"dist_actor\"], self.store_[\"action_actor\"]\n            dist_control, action_control = self.store_[\"dist_controller\"], self.store_[\"action_controller\"]\n\n            log_prob_actor = dist_actor.log_prob(action_actor)\n            log_prob_control = dist_control.log_prob(action_control)\n\n            log_prob = log_prob_actor + log_prob_control  \n\n        elif self.actor_:\n            dist, action = self.store_[\"dist_actor\"], self.store_[\"action_actor\"]\n            log_prob = dist.log_prob(action)\n\n        elif self.control_:\n            dist, action = self.store_[\"dist_controller\"], self.store_[\"action_controller\"]\n            log_prob = dist.log_prob(action)\n\n        actor_loss = -(log_prob * (td_target - prev_value.detach())).mean()\n\n        self.actor_optimizer.zero_grad()\n        actor_loss.backward()\n        self.actor_optimizer.step()\n\n        critic_loss = torch.nn.functional.mse_loss(td_target, prev_value)\n        self.critic_optimizer.zero_grad()\n        critic_loss.backward()\n        self.critic_optimizer.step()\n\n        return actor_loss, critic_loss","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T17:25:14.975132Z","iopub.execute_input":"2025-09-18T17:25:14.975328Z","iopub.status.idle":"2025-09-18T17:25:14.992007Z","shell.execute_reply.started":"2025-09-18T17:25:14.975308Z","shell.execute_reply":"2025-09-18T17:25:14.991429Z"}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"### Dataset\n+ Class weights\n+ Dataset class","metadata":{}},{"cell_type":"code","source":"class XRayDataset(Dataset):\n\n    def __init__(self, df, train=True, transform=None):\n        super().__init__()\n        self.df = df\n        self.train = train\n        self.transform = transform\n        self.label_columns = [\n            'Atelectasis', 'Cardiomegaly', 'Consolidation', 'Edema', 'Enlarged Cardiomediastinum',\n            'Fracture', 'Lung Lesion', 'Lung Opacity', 'No Finding', 'Pleural Effusion',\n            'Pleural Other', 'Pneumonia', 'Pneumothorax', 'Support Devices'\n        ]\n        \n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        img_path = self.df.iloc[idx][\"img_path\"]\n        img = Image.open(img_path).convert(\"RGB\")\n        label = self.df.iloc[idx][self.label_columns].values.astype(np.float32)\n        key = self.df.iloc[idx][\"Image_name\"]\n        \n        if self.train and self.transform is not None:\n            img = self.transform(key, img)\n\n        img = basic_transforms(img)\n\n        if not self.train:\n            return key, img\n\n        return key, img, torch.tensor(label, dtype=torch.float32)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T17:25:14.992631Z","iopub.execute_input":"2025-09-18T17:25:14.992889Z","iopub.status.idle":"2025-09-18T17:25:15.010802Z","shell.execute_reply.started":"2025-09-18T17:25:14.992864Z","shell.execute_reply":"2025-09-18T17:25:15.010026Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"def get_class_weights(df):\n    weights = []\n    label_columns = [\n        'Atelectasis', 'Cardiomegaly', 'Consolidation', 'Edema', 'Enlarged Cardiomediastinum',\n        'Fracture', 'Lung Lesion', 'Lung Opacity', 'No Finding', 'Pleural Effusion',\n        'Pleural Other', 'Pneumonia', 'Pneumothorax', 'Support Devices'\n    ]\n\n    for label in label_columns:\n        percent = df[label].sum() / len(df)\n        weights.append(percent)\n    return weights","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T17:25:15.011418Z","iopub.execute_input":"2025-09-18T17:25:15.011587Z","iopub.status.idle":"2025-09-18T17:25:15.024850Z","shell.execute_reply.started":"2025-09-18T17:25:15.011573Z","shell.execute_reply":"2025-09-18T17:25:15.024179Z"}},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":"### Adapt entire Model to new dataset","metadata":{}},{"cell_type":"code","source":"train_csv = pd.read_csv(\"/kaggle/input/grand-xray-slam-division-a/train1.csv\")\ntrain_csv[\"img_path\"] = train_csv[\"Image_name\"].apply(lambda x: os.path.join(BASE_DIR, \"train1\", x))\nsubmission_df = pd.read_csv(\"/kaggle/input/grand-xray-slam-division-a/sample_submission_1.csv\")\ntrain_df, val_df = train_test_split(\n    train_csv,\n    test_size=0.2,\n    random_state=42,\n    stratify=train_csv[\"No Finding\"]\n)\n\nsubmission_df[\"img_path\"] = submission_df[\"Image_name\"].apply(lambda x : os.path.join(BASE_DIR, \"test1\", x))\nclass_weights = get_class_weights(train_df)\nzipped_class_weights = list(zip(label_columns, class_weights))\n\nfor class_, weight in zipped_class_weights:\n    print(f\"{class_}: {weight:.3f}\\n\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T17:25:38.230018Z","iopub.execute_input":"2025-09-18T17:25:38.230507Z","iopub.status.idle":"2025-09-18T17:25:38.736947Z","shell.execute_reply.started":"2025-09-18T17:25:38.230478Z","shell.execute_reply":"2025-09-18T17:25:38.736313Z"}},"outputs":[{"name":"stdout","text":"Atelectasis: 0.362\n\nCardiomegaly: 0.325\n\nConsolidation: 0.273\n\nEdema: 0.248\n\nEnlarged Cardiomediastinum: 0.352\n\nFracture: 0.138\n\nLung Lesion: 0.110\n\nLung Opacity: 0.452\n\nNo Finding: 0.316\n\nPleural Effusion: 0.319\n\nPleural Other: 0.066\n\nPneumonia: 0.132\n\nPneumothorax: 0.082\n\nSupport Devices: 0.351\n\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"# Dataset\nada_augment=AdaAugment(rand_m=True, rand_t=False)\ntrain_set = XRayDataset(train_df, train=True)\nval_set = XRayDataset(val_df, train=True)\ntest_set = XRayDataset(submission_df, train=False)\n\n# DataLoader\nbatch_size = 32\ntrain_loader = DataLoader(\n    train_set, \n    batch_size=batch_size, \n    shuffle=True, \n    pin_memory=True,\n    num_workers=os.cpu_count()\n)\nval_loader = DataLoader(\n    val_set, \n    batch_size=batch_size, \n    pin_memory=True,\n    num_workers=os.cpu_count()\n)\ntest_loader = DataLoader(\n    test_set, \n    batch_size=batch_size, \n    pin_memory=True,\n    num_workers=os.cpu_count()\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T17:35:14.625251Z","iopub.execute_input":"2025-09-18T17:35:14.625864Z","iopub.status.idle":"2025-09-18T17:35:14.630983Z","shell.execute_reply.started":"2025-09-18T17:35:14.625838Z","shell.execute_reply":"2025-09-18T17:35:14.630409Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"# Models and functions\n\nmodel = get_effnetb0(fine_tune=False)\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\nbce_loss = torch.nn.BCEWithLogitsLoss(pos_weight=torch.tensor(class_weights).to(device))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T17:34:03.052059Z","iopub.execute_input":"2025-09-18T17:34:03.052551Z","iopub.status.idle":"2025-09-18T17:34:03.192381Z","shell.execute_reply.started":"2025-09-18T17:34:03.052527Z","shell.execute_reply":"2025-09-18T17:34:03.191602Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"epochs = 3\nmodel.to(device)\n\nif torch.cuda.device_count() > 1:\n    print(f\"Using {torch.cuda.device_count()} GPUs\")\n    model = nn.DataParallel(model)\n    \nfor epoch in range(epochs):\n    \n    # Training\n    \n    model.train()\n    train_loss = 0\n    for keys, imgs, targets in tqdm(train_loader, desc=\"Training\"):\n        imgs, targets = imgs.to(device, non_blocking=True), targets.to(device, non_blocking=True)\n\n        logits = model(imgs)\n        loss = bce_loss(logits, targets)\n\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        train_loss += loss.item()\n    train_loss /= len(train_loader)\n\n    # Validation\n    model.eval()\n    val_loss = 0\n\n    all_probs = []\n    all_targets = []\n\n    with torch.inference_mode():\n        for keys, imgs, targets in tqdm(val_loader, desc=\"Validation\"):\n            imgs, targets = imgs.to(device, non_blocking=True), targets.to(device, non_blocking=True)\n\n            logits = model(imgs)\n            loss = bce_loss(logits, targets)\n            probs = torch.sigmoid(logits)\n\n            val_loss += loss.item()\n\n            all_probs.append(probs)\n            all_targets.append(targets)\n\n    val_loss /= len(val_loader)\n    all_probs = torch.cat(all_probs, dim=0)\n    all_targets = torch.cat(all_targets, dim=0)\n\n    val_accuracy  = accuracy(all_probs, all_targets.int(), task=\"multilabel\", num_labels=14)\n    val_precision = precision(all_probs, all_targets.int(), task=\"multilabel\", num_labels=14)\n    val_recall    = recall(all_probs, all_targets.int(), task=\"multilabel\", num_labels=14)\n    val_auroc     = auroc(all_probs, all_targets.int(), task=\"multilabel\", num_labels=14)\n\n    print(\n        f\"Epoch {epoch+1}/{epochs} | \"\n        f\"Train Loss: {train_loss:.4f} | \"\n        f\"Val Loss: {val_loss:.4f} | \"\n        f\"Acc: {val_accuracy:.4f} | \"\n        f\"Prec: {val_precision:.4f} | \"\n        f\"Rec: {val_recall:.4f} | \"\n        f\"AUROC: {val_auroc:.4f}\"\n    )\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T17:35:58.699079Z","iopub.execute_input":"2025-09-18T17:35:58.699652Z","iopub.status.idle":"2025-09-18T17:42:05.772903Z","shell.execute_reply.started":"2025-09-18T17:35:58.699631Z","shell.execute_reply":"2025-09-18T17:42:05.771840Z"}},"outputs":[{"name":"stderr","text":"Training:  18%|█▊        | 489/2685 [06:06<27:28,  1.33it/s]\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_36/1906783998.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Training\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mimgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1181\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1182\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1183\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 708\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    709\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m             if (\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1457\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1459\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1408\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1410\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1411\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1412\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1249\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1250\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1251\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1252\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1253\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    178\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m             \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":29},{"cell_type":"markdown","source":"### Finetuning using AdaAugment and Focal Loss","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}