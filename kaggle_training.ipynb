{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-21T09:53:33.758806Z",
     "iopub.status.busy": "2025-09-21T09:53:33.758598Z",
     "iopub.status.idle": "2025-09-21T09:53:51.858428Z",
     "shell.execute_reply": "2025-09-21T09:53:51.857680Z",
     "shell.execute_reply.started": "2025-09-21T09:53:33.758782Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models, transforms\n",
    "from torchmetrics.functional import accuracy, recall, precision, auroc\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import timm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from typing import List\n",
    "from tqdm import tqdm\n",
    "from torchmetrics.functional import accuracy, recall, precision, auroc\n",
    "from PIL import Image, ImageEnhance, ImageOps, ImageFilter\n",
    "import os\n",
    "from glob import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "BASE_DIR = \"/kaggle/input/grand-xray-slam-division-a\"\n",
    "label_columns = [\n",
    "    'Atelectasis', 'Cardiomegaly', 'Consolidation', 'Edema', 'Enlarged Cardiomediastinum',\n",
    "    'Fracture', 'Lung Lesion', 'Lung Opacity', 'No Finding', 'Pleural Effusion',\n",
    "    'Pleural Other', 'Pneumonia', 'Pneumothorax', 'Support Devices'\n",
    "]\n",
    "\n",
    "\n",
    "def setup_seed(seed=None):\n",
    "    if seed is None:\n",
    "        return\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Augmentation Spaces and Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-21T09:53:51.860470Z",
     "iopub.status.busy": "2025-09-21T09:53:51.860036Z",
     "iopub.status.idle": "2025-09-21T09:53:51.869727Z",
     "shell.execute_reply": "2025-09-21T09:53:51.869012Z",
     "shell.execute_reply.started": "2025-09-21T09:53:51.860451Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# used to freeze layers in a model\n",
    "def freeze_all(model):\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad=False\n",
    "\n",
    "def get_resnet18(num_classes=14, fine_tune=True):\n",
    "    model = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
    "\n",
    "    if fine_tune:\n",
    "        freeze_all(model)\n",
    "        for param in model.layer4.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "    model.fc = nn.Linear(512, num_classes)\n",
    "    return model\n",
    "\n",
    "def get_resnet34(num_classes=14, fine_tune=True):\n",
    "    model = models.resnet34(weights=models.ResNet34_Weights.IMAGENET1K_V1)\n",
    "\n",
    "    if fine_tune:\n",
    "        freeze_all(model)\n",
    "        for param in model.layer4.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "    model.fc = nn.Linear(512, num_classes)\n",
    "    return model\n",
    "\n",
    "def get_effnetb0(num_classes=14, fine_tune=True):\n",
    "    model = models.efficientnet_b0(weights=models.EfficientNet_B0_Weights.IMAGENET1K_V1)\n",
    "\n",
    "    if fine_tune:\n",
    "        freeze_all(model)\n",
    "        for idx in range(6, 8):\n",
    "            for param in model.features[idx].parameters():\n",
    "                param.requires_grad = True\n",
    "\n",
    "    model.classifier = nn.Sequential(\n",
    "        nn.Dropout(p=0.2, inplace=True),\n",
    "        nn.Linear(in_features=1280, out_features=num_classes)\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "def get_convnext_tiny(num_classes=14, fine_tune=True):\n",
    "    model = models.convnext_tiny(weights=models.ConvNeXt_Tiny_Weights.IMAGENET1K_V1)\n",
    "\n",
    "    if fine_tune:\n",
    "        freeze_all(model)\n",
    "        for param in model.features[6].parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "    model.classifier[2] = nn.Linear(in_features=768, out_features=num_classes)\n",
    "    return model\n",
    "\n",
    "# returns getter function and number of in features of the classifier\n",
    "models_ = {\n",
    "    \"res18\": (get_resnet18, 512),\n",
    "    \"res34\": (get_resnet34, 512),\n",
    "    \"effb0\": (get_effnetb0, 1280),\n",
    "    \"convnext\" : (get_convnext_tiny, 768),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-21T09:53:51.870884Z",
     "iopub.status.busy": "2025-09-21T09:53:51.870571Z",
     "iopub.status.idle": "2025-09-21T09:53:51.899438Z",
     "shell.execute_reply": "2025-09-21T09:53:51.898759Z",
     "shell.execute_reply.started": "2025-09-21T09:53:51.870856Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Set up transforms\n",
    "basic_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)), # resize to 224x224\n",
    "    transforms.ToTensor(), # convert to tensor [0,1]\n",
    "    transforms.Normalize( # normalize with ImageNet stats\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])\n",
    "\n",
    "# custom transforms with adaptive magnitude\n",
    "def shear_x(img, magnitude):\n",
    "    level = magnitude * 0.3 * random.choice([-1, 1])\n",
    "    return img.transform(img.size, Image.AFFINE, (1, level, 0, 0, 1, 0))\n",
    "\n",
    "def shear_y(img, magnitude):\n",
    "    level = magnitude * 0.3 * random.choice([-1, 1])\n",
    "    return img.transform(img.size, Image.AFFINE, (1, 0, 0, level, 1, 0))\n",
    "\n",
    "def translate_x(img, magnitude):\n",
    "    max_shift = 0.3 * img.size[0]\n",
    "    level = magnitude * max_shift * random.choice([-1, 1])\n",
    "    return img.transform(img.size, Image.AFFINE, (1, 0, level, 0, 1, 0))\n",
    "\n",
    "def translate_y(img, magnitude):\n",
    "    max_shift = 0.3 * img.size[1]\n",
    "    level = magnitude * max_shift * random.choice([-1, 1])\n",
    "    return img.transform(img.size, Image.AFFINE, (1, 0, 0, 0, 1, level))\n",
    "\n",
    "def rotate(img, magnitude):\n",
    "    degrees = magnitude * 30 * random.choice([-1, 1])\n",
    "    return img.rotate(degrees)\n",
    "\n",
    "def contrast(img, magnitude):\n",
    "    enhancer = ImageEnhance.Contrast(img)\n",
    "    factor = 1.0 + (magnitude * random.choice([-0.9, 0.9]))\n",
    "    return enhancer.enhance(factor)\n",
    "\n",
    "def brightness(img, magnitude):\n",
    "    enhancer = ImageEnhance.Brightness(img)\n",
    "    factor = 1.0 + (magnitude * random.choice([-0.9, 0.9]))\n",
    "    return enhancer.enhance(factor)\n",
    "\n",
    "def sharpness(img, magnitude):\n",
    "    enhancer = ImageEnhance.Sharpness(img)\n",
    "    factor = 1.0 + (magnitude * random.choice([-0.9, 0.9]))\n",
    "    return enhancer.enhance(factor)\n",
    "\n",
    "def equalize(img, magnitude=None):\n",
    "    return ImageOps.equalize(img)\n",
    "\n",
    "def gaussian_blur(img, magnitude):\n",
    "    radius = magnitude * 2\n",
    "    return img.filter(ImageFilter.GaussianBlur(radius))\n",
    "\n",
    "def identity(img, magnitude=None):\n",
    "    return img\n",
    "\n",
    "augmentation_space = [\n",
    "    shear_x, shear_y, \n",
    "    translate_x, translate_y,\n",
    "    rotate, equalize, \n",
    "    contrast, brightness,\n",
    "    sharpness, identity\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-21T09:53:51.900396Z",
     "iopub.status.busy": "2025-09-21T09:53:51.900201Z",
     "iopub.status.idle": "2025-09-21T09:53:51.920120Z",
     "shell.execute_reply": "2025-09-21T09:53:51.919523Z",
     "shell.execute_reply.started": "2025-09-21T09:53:51.900377Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# AdaAugment can be used to control augmentation magnitudes and operations\n",
    "\n",
    "\n",
    "class AdaAugment:\n",
    "\n",
    "    def __init__(self, rand_m, rand_t):\n",
    "        self.key_transform = {}\n",
    "        self.key_magnitude = {}\n",
    "        self.transforms = [\n",
    "            shear_x, shear_y, \n",
    "            translate_x, translate_y,\n",
    "            rotate, equalize, \n",
    "            contrast, brightness,\n",
    "            sharpness, identity\n",
    "        ]\n",
    "        self.rand_m = rand_m\n",
    "        self.rand_t = rand_t\n",
    "\n",
    "    def set(self, keys, m=None, transform_idx=None):\n",
    "        if m is not None:\n",
    "            for i, key in enumerate(keys):\n",
    "                self.key_magnitude[key] = m[i].cpu().detach()\n",
    "            \n",
    "        if transform_idx is not None:\n",
    "            for i, key in enumerate(keys):\n",
    "                self.key_transform[key] = transform_idx[i].cpu().detach()\n",
    "    \n",
    "    def __call__(self, key, img):\n",
    "        \"\"\"\n",
    "        Apply an augmentation to the image based on stored magnitudes and transforms.\n",
    "        \n",
    "        Args:\n",
    "            key: unique identifier for the sample\n",
    "            img: input image to transform\n",
    "    \n",
    "        Returns:\n",
    "            Augmented image\n",
    "        \"\"\"\n",
    "        # --- Determine magnitude ---\n",
    "        magnitude = self.key_magnitude.get(key)\n",
    "        \n",
    "        if magnitude is None:\n",
    "            # No stored magnitude\n",
    "            if self.rand_m:\n",
    "                # Random magnitude\n",
    "                if random.random() < 0.6:\n",
    "                    return img  # skip transform 40% of the time\n",
    "                magnitude = random.random()\n",
    "            else:\n",
    "                magnitude = 0.0\n",
    "        else:\n",
    "            # Magnitude exists\n",
    "            if not self.rand_m and not self.rand_t:\n",
    "                # Use magnitude corresponding to stored transform index\n",
    "                transform_idx = int(self.key_transform.get(key))\n",
    "                if isinstance(magnitude, (list, torch.Tensor)):\n",
    "                    magnitude = float(magnitude[transform_idx])\n",
    "                else:\n",
    "                    magnitude = float(magnitude)\n",
    "            else:\n",
    "                magnitude = float(magnitude)\n",
    "    \n",
    "        # --- Determine transform ---\n",
    "        transform_idx = self.key_transform.get(key)\n",
    "        \n",
    "        if transform_idx is None:\n",
    "            # No stored transform\n",
    "            transform = random.choice(self.transforms) if self.rand_t else self.transforms[-1]\n",
    "        else:\n",
    "            transform = self.transforms[int(transform_idx)]\n",
    "    \n",
    "        # --- Apply transform ---\n",
    "        return transform(img, magnitude)\n",
    "\n",
    "\n",
    "class SimpleAugment:\n",
    "\n",
    "    def __init__(self, p=0.6, keys=None):\n",
    "        self.keys = keys\n",
    "        self.key_transform = {}\n",
    "        self.key_magnitude = {}\n",
    "        self.transforms = [\n",
    "            shear_x, shear_y, \n",
    "            translate_x, translate_y,\n",
    "            rotate, equalize, \n",
    "            contrast, brightness, \n",
    "            sharpness, identity\n",
    "        ]\n",
    "        self.transform_idx = list(range(len(self.transforms)))\n",
    "        self.p = p\n",
    "\n",
    "    def get(self, keys):\n",
    "        collected_magnitude = []\n",
    "        collected_transform = []\n",
    "        collected_keys = []\n",
    "        for key in keys:\n",
    "            if key in self.keys:\n",
    "                collected_keys.append(key)\n",
    "                collected_magnitude.append(self.key_magnitude[key])\n",
    "                collected_transform.append(self.key_transform[key])\n",
    "        return collected_keys, torch.stack(collected_transform), torch.stack(collected_magnitude)\n",
    "        \n",
    "    def __call__(self, key, img):\n",
    "        \"\"\"\n",
    "        Apply simple reandom augmentations to an image\n",
    "        \n",
    "        Args:\n",
    "            key: unique identifier for the sample\n",
    "            img: input image to transform\n",
    "    \n",
    "        Returns:\n",
    "            Augmented image\n",
    "        \"\"\"\n",
    "        if random.random() < self.p and key in self.keys:\n",
    "            transform_idx = random.choice(self.transform_idx)\n",
    "            transform = self.transforms[transform_idx]\n",
    "            magnitude = random.random()\n",
    "            self.key_transform[key] = transform_idx\n",
    "            self.key_magnitude[key] = magnitude\n",
    "            return transform(img, magnitude)\n",
    "\n",
    "        else:\n",
    "            return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-21T09:53:51.922430Z",
     "iopub.status.busy": "2025-09-21T09:53:51.921822Z",
     "iopub.status.idle": "2025-09-21T09:53:51.939080Z",
     "shell.execute_reply": "2025-09-21T09:53:51.938513Z",
     "shell.execute_reply.started": "2025-09-21T09:53:51.922412Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Focal Loss for fine tuninng\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "\n",
    "    def __init__(self, weights:List=None, gamma=2.0, reduction=\"mean\"):\n",
    "        super().__init__()\n",
    "\n",
    "        self.weights = weights.to(device)\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, logit, target):\n",
    "        bce_loss = nn.functional.binary_cross_entropy_with_logits(\n",
    "            logit, target,\n",
    "            reduction=\"none\"\n",
    "        )\n",
    "        probs = torch.exp(-bce_loss)\n",
    "        F_loss = self.weights.to(target.device) * (1-probs) ** self.gamma * bce_loss\n",
    "\n",
    "        if self.reduction == \"mean\":\n",
    "            return F_loss.mean()\n",
    "        elif self.reduction == \"none\":\n",
    "            return F_loss   \n",
    "        else:\n",
    "            return F_loss.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-21T09:53:51.940318Z",
     "iopub.status.busy": "2025-09-21T09:53:51.939893Z",
     "iopub.status.idle": "2025-09-21T09:53:51.955784Z",
     "shell.execute_reply": "2025-09-21T09:53:51.955155Z",
     "shell.execute_reply.started": "2025-09-21T09:53:51.940301Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Saves per sample information such as previous loss etc.\n",
    "\n",
    "class ValueMemory:\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Stores the last value per key (no EMA).\n",
    "        \"\"\"\n",
    "        self.values = {}\n",
    "\n",
    "    def __call__(self, keys, vals):\n",
    "        \"\"\"\n",
    "        keys: list of sample identifiers\n",
    "        vals: torch.Tensor of shape (len(keys), D)\n",
    "        Returns: current stored values, previous stored values\n",
    "        \"\"\"\n",
    "        stored_list = []\n",
    "        new_list = []\n",
    "\n",
    "        for i, key in enumerate(keys):\n",
    "            val = vals[i]\n",
    "            if key not in self.values:\n",
    "                old = val.clone()  # nothing stored yet → use current\n",
    "            else:\n",
    "                old = self.values[key]\n",
    "\n",
    "            self.values[key] = val  # overwrite with last value\n",
    "\n",
    "            stored_list.append(old.unsqueeze(0))\n",
    "            new_list.append(self.values[key].unsqueeze(0))\n",
    "\n",
    "        stored = torch.cat(stored_list, dim=0)  # previous values\n",
    "        return stored\n",
    "\n",
    "    def get(self, key):\n",
    "        \"\"\"\n",
    "        Access the stored value for a single key\n",
    "        \"\"\"\n",
    "        return self.values.get(key, None)\n",
    "\n",
    "    def get_multi(self, keys):\n",
    "        \"\"\"\n",
    "        Access stored values for multiple keys\n",
    "        \"\"\"\n",
    "        return torch.stack([self.values[k] for k in keys])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up the AdaAugment Agent\n",
    "+ Critic => returns value for a state\n",
    "+ Actor => Parameterizes a beta distribution that is used to sample augmentation magnitudes\n",
    "+ Controller => Parameterizes a categorical distribution that is used to sample transformations from the augmentation space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-21T09:53:51.956658Z",
     "iopub.status.busy": "2025-09-21T09:53:51.956441Z",
     "iopub.status.idle": "2025-09-21T09:53:51.976354Z",
     "shell.execute_reply": "2025-09-21T09:53:51.975519Z",
     "shell.execute_reply.started": "2025-09-21T09:53:51.956644Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class Actor(nn.Module):\n",
    "    def __init__(self, in_features, hidden, out_features):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(in_features, hidden)\n",
    "        self.layernorm1 = nn.LayerNorm(hidden)\n",
    "        self.linear2 = nn.Linear(hidden, hidden)\n",
    "        #self.layernorm2 = nn.LayerNorm(hidden)\n",
    "        self.alpha_head = nn.Linear(hidden, out_features)\n",
    "        self.beta_head = nn.Linear(hidden, out_features)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.layernorm1(self.linear1(x)))\n",
    "        x = torch.relu(self.linear2(x))\n",
    "        return torch.softmax(self.alpha_head(x), dim=-1) + 1, torch.softmax(self.beta_head(x), dim=-1) + 1\n",
    "\n",
    "    def get_dist(self, x):\n",
    "        alpha, beta = self(x)\n",
    "        dist = torch.distributions.Beta(alpha, beta)\n",
    "        return dist\n",
    "\n",
    "\n",
    "class Critic(nn.Module):\n",
    "\n",
    "    def __init__(self, in_features, hidden):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(in_features, hidden)\n",
    "        self.layernorm1 = nn.LayerNorm(hidden)\n",
    "        self.linear2 = nn.Linear(hidden, hidden)\n",
    "        #self.layernorm2 = nn.LayerNorm(hidden)\n",
    "        self.head = nn.Linear(hidden, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.layernorm1(self.linear1(x)))\n",
    "        x = torch.relu(self.linear2(x))\n",
    "        x = self.head(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Controller(nn.Module):\n",
    "\n",
    "    def __init__(self, in_features, hidden):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(in_features, hidden)\n",
    "        self.layernorm1 = nn.LayerNorm(hidden)\n",
    "        self.linear2 = nn.Linear(hidden, hidden)\n",
    "        #self.layernorm2 = nn.LayerNorm(hidden)\n",
    "        self.head = nn.Linear(hidden, len(augmentation_space))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.layernorm1(self.linear1(x)))\n",
    "        x = torch.relu(self.linear2(x))\n",
    "        x = self.head(x)\n",
    "        return x\n",
    "    \n",
    "    def get_dist(self, x):\n",
    "        out = self(x)\n",
    "        dist = torch.distributions.Categorical(logits=out)\n",
    "        return dist\n",
    "\n",
    "\n",
    "class Agent(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "        self, \n",
    "        in_features,\n",
    "        out_features, \n",
    "        control=False, \n",
    "        actor=False, \n",
    "        advantage_reg=True,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.val_memory = ValueMemory()\n",
    "        self.loss_memory = ValueMemory()\n",
    "        self.advantage_reg = advantage_reg\n",
    "\n",
    "        self.critic = Critic(in_features=in_features, hidden=128)\n",
    "\n",
    "        self.store_ = {}\n",
    "\n",
    "        self.control_ = control\n",
    "        self.actor_ = actor\n",
    "        if control:\n",
    "            self.controller = Controller(in_features=in_features, hidden=128)\n",
    "            self.controller_optimizer = torch.optim.Adam(\n",
    "                params=self.controller.parameters(), lr=3e-5, weight_decay=5e-4\n",
    "            )\n",
    "\n",
    "        if actor:\n",
    "            self.actor = Actor(in_features=in_features, hidden=128, out_features=out_features) \n",
    "\n",
    "            self.actor_optimizer = torch.optim.Adam(\n",
    "                params=self.actor.parameters(), lr=3e-5, weight_decay=5e-4\n",
    "            )\n",
    "        self.critic_optimizer = torch.optim.Adam(\n",
    "            params=self.critic.parameters(), lr=3e-5, weight_decay=5e-4\n",
    "        )\n",
    "\n",
    "    def forward(self, state):\n",
    "        action_actor = None\n",
    "        action_controller = None\n",
    "\n",
    "        if self.actor_:  \n",
    "            dist = self.actor.get_dist(state.detach())\n",
    "            action_actor = dist.sample()\n",
    "            self.store_[\"action_actor\"] = action_actor\n",
    "            self.store_[\"dist_actor\"] = dist\n",
    "\n",
    "        if self.control_:\n",
    "            dist = self.controller.get_dist(state.detach())\n",
    "            action_controller = dist.sample()\n",
    "            self.store_[\"action_controller\"] = action_controller\n",
    "            self.store_[\"dist_controller\"] = dist\n",
    "\n",
    "        return action_actor, action_controller       \n",
    "    \n",
    "    def set_action(self, action_actor, action_controller):\n",
    "        self.store_[\"action_controller\"] = action_controller\n",
    "        self.store_[\"action_actor\"] = action_actor\n",
    "\n",
    "    def update(self, key, state, reward):\n",
    "        value = self.critic(state)\n",
    "        prev_state = self.val_memory(key, state)\n",
    "        prev_value = self.critic(prev_state)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            td_target = reward + 0.99 * value\n",
    "\n",
    "        if self.actor_ and self.control_:\n",
    "            dist_actor, action_actor = self.store_[\"dist_actor\"], self.store_[\"action_actor\"]\n",
    "            dist_control, action_control = self.store_[\"dist_controller\"], self.store_[\"action_controller\"]\n",
    "        \n",
    "            # Select magnitude corresponding to the chosen augmentation\n",
    "            chosen_magnitude = action_actor.gather(1, action_control.unsqueeze(1))\n",
    "\n",
    "            # Controller chooses augmentation index\n",
    "            aug_idx = action_control.unsqueeze(1)\n",
    "            \n",
    "            # Select alpha, beta for chosen augmentation\n",
    "            alpha_chosen = dist_actor.concentration1.gather(1, aug_idx)\n",
    "            beta_chosen  = dist_actor.concentration0.gather(1, aug_idx)\n",
    "            \n",
    "            # Build a Beta distribution only for the chosen augmentation\n",
    "            dist_chosen = torch.distributions.Beta(alpha_chosen.squeeze(1), beta_chosen.squeeze(1))\n",
    "            \n",
    "            # Compute log_prob of chosen magnitude\n",
    "            log_prob_actor = dist_chosen.log_prob(chosen_magnitude.squeeze(1))\n",
    "        \n",
    "            # Log-prob for augmentation choice\n",
    "            log_prob_control = dist_control.log_prob(action_control)\n",
    "        \n",
    "            # Total log prob\n",
    "            log_prob = log_prob_actor + log_prob_control\n",
    "\n",
    "        elif self.actor_:\n",
    "            dist, action = self.store_[\"dist_actor\"], self.store_[\"action_actor\"]\n",
    "            log_prob = dist.log_prob(action)\n",
    "\n",
    "        elif self.control_:\n",
    "            dist, action = self.store_[\"dist_controller\"], self.store_[\"action_controller\"]\n",
    "            log_prob = dist.log_prob(action)\n",
    "\n",
    "        advantage = td_target - prev_value.detach()\n",
    "\n",
    "        if self.advantage_reg:\n",
    "            advantage = (advantage - advantage.mean()) (advantage.std() + 1e-8)\n",
    "\n",
    "        actor_loss = -(log_prob * advantage).mean()\n",
    "\n",
    "        if self.control_:\n",
    "            self.controller_optimizer.zero_grad()\n",
    "        if self.actor_:\n",
    "            self.actor_optimizer.zero_grad()\n",
    "        actor_loss.backward()\n",
    "        if self.actor_:\n",
    "            self.actor_optimizer.step()\n",
    "        if self.control_:\n",
    "            self.controller_optimizer.step()\n",
    "        critic_loss = torch.nn.functional.mse_loss(td_target, prev_value)\n",
    "        self.critic_optimizer.zero_grad()\n",
    "        critic_loss.backward()\n",
    "        self.critic_optimizer.step()\n",
    "\n",
    "        return actor_loss, critic_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "+ Class weights\n",
    "+ Dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-21T09:53:51.977763Z",
     "iopub.status.busy": "2025-09-21T09:53:51.977469Z",
     "iopub.status.idle": "2025-09-21T09:53:51.993378Z",
     "shell.execute_reply": "2025-09-21T09:53:51.992883Z",
     "shell.execute_reply.started": "2025-09-21T09:53:51.977737Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def get_class_weights(df):\n",
    "    weights = []\n",
    "    label_columns = [\n",
    "        'Atelectasis', 'Cardiomegaly', 'Consolidation', 'Edema', 'Enlarged Cardiomediastinum',\n",
    "        'Fracture', 'Lung Lesion', 'Lung Opacity', 'No Finding', 'Pleural Effusion',\n",
    "        'Pleural Other', 'Pneumonia', 'Pneumothorax', 'Support Devices'\n",
    "    ]\n",
    "\n",
    "    for label in label_columns:\n",
    "        weight = len(df) / (df[label].sum() + 1e-6)\n",
    "        weights.append(weight)\n",
    "\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-21T09:53:51.994228Z",
     "iopub.status.busy": "2025-09-21T09:53:51.993998Z",
     "iopub.status.idle": "2025-09-21T09:53:52.013459Z",
     "shell.execute_reply": "2025-09-21T09:53:52.012830Z",
     "shell.execute_reply.started": "2025-09-21T09:53:51.994213Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class XRayDataset(Dataset):\n",
    "\n",
    "    def __init__(self, df, train=True, transform=None):\n",
    "        super().__init__()\n",
    "        self.df = df\n",
    "        self.train = train\n",
    "        self.transform = transform\n",
    "        self.label_columns = [\n",
    "            'Atelectasis', 'Cardiomegaly', 'Consolidation', 'Edema', 'Enlarged Cardiomediastinum',\n",
    "            'Fracture', 'Lung Lesion', 'Lung Opacity', 'No Finding', 'Pleural Effusion',\n",
    "            'Pleural Other', 'Pneumonia', 'Pneumothorax', 'Support Devices'\n",
    "        ]\n",
    "        if train:\n",
    "            class_weights = np.array(get_class_weights(df), dtype=np.float32)\n",
    "    \n",
    "            sample_weights = (df[label_columns].values.astype(np.float32) * class_weights).mean(axis=1)\n",
    "            sample_weights[sample_weights == 0] = 1.0\n",
    "            self.df[\"weight\"] = sample_weights\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.df.iloc[idx][\"img_path\"]\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        label = self.df.iloc[idx][self.label_columns].values.astype(np.float32)\n",
    "        key = self.df.iloc[idx][\"Image_name\"]\n",
    "        \n",
    "        if self.train and self.transform is not None:\n",
    "            img = self.transform(key, img)\n",
    "\n",
    "        img = basic_transforms(img)\n",
    "\n",
    "        if not self.train:\n",
    "            return key, img\n",
    "\n",
    "        return key, img, torch.tensor(label, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adapt model to new dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-21T09:53:52.014420Z",
     "iopub.status.busy": "2025-09-21T09:53:52.014183Z",
     "iopub.status.idle": "2025-09-21T09:53:52.635969Z",
     "shell.execute_reply": "2025-09-21T09:53:52.635215Z",
     "shell.execute_reply.started": "2025-09-21T09:53:52.014406Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Atelectasis: 2.765\n",
      "\n",
      "Cardiomegaly: 3.073\n",
      "\n",
      "Consolidation: 3.666\n",
      "\n",
      "Edema: 4.034\n",
      "\n",
      "Enlarged Cardiomediastinum: 2.841\n",
      "\n",
      "Fracture: 7.221\n",
      "\n",
      "Lung Lesion: 9.104\n",
      "\n",
      "Lung Opacity: 2.211\n",
      "\n",
      "No Finding: 3.162\n",
      "\n",
      "Pleural Effusion: 3.137\n",
      "\n",
      "Pleural Other: 15.225\n",
      "\n",
      "Pneumonia: 7.571\n",
      "\n",
      "Pneumothorax: 12.202\n",
      "\n",
      "Support Devices: 2.852\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_csv = pd.read_csv(\"/kaggle/input/grand-xray-slam-division-a/train1.csv\")\n",
    "train_csv[\"img_path\"] = train_csv[\"Image_name\"].apply(lambda x: os.path.join(BASE_DIR, \"train1\", x))\n",
    "submission_df = pd.read_csv(\"/kaggle/input/grand-xray-slam-division-a/sample_submission_1.csv\")\n",
    "train_df, val_df = train_test_split(\n",
    "    train_csv,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=train_csv[\"No Finding\"]\n",
    ")\n",
    "\n",
    "submission_df[\"img_path\"] = submission_df[\"Image_name\"].apply(lambda x : os.path.join(BASE_DIR, \"test1\", x))\n",
    "class_weights = get_class_weights(train_df)\n",
    "zipped_class_weights = list(zip(label_columns, class_weights))\n",
    "\n",
    "print(\"Train dataset:\")\n",
    "for class_, weight in zipped_class_weights:\n",
    "    print(f\"{class_}: {weight:.2f}\\n\")\n",
    "\n",
    "\n",
    "print(\"Validation dataset:\")\n",
    "\n",
    "class_weights = get_class_weights(val_df)\n",
    "zipped_class_weights = list(zip(label_columns, class_weights))\n",
    "for class_, weight in zipped_class_weights:\n",
    "    print(f\"{class_}: {weight:.2f}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_state = {}\n",
    "def _register_head_hook(model):\n",
    "    def hook(module, input, output):\n",
    "        current_state['head_input'] = input[0].detach()\n",
    "    \n",
    "    if isinstance(model, models.EfficientNet):\n",
    "        return model.classifier[-1].register_forward_hook(hook)\n",
    "    elif isinstance(model, models.ConvNeXt):\n",
    "        return model.classifier[2].register_forward_hook(hook)\n",
    "    else:\n",
    "        return model.classifier[-1].register_forward_hook(hook)\n",
    "\n",
    "def _remove_head_hook(_hook_handle):\n",
    "    _hook_handle.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-21T09:53:52.637056Z",
     "iopub.status.busy": "2025-09-21T09:53:52.636753Z",
     "iopub.status.idle": "2025-09-21T09:53:52.672013Z",
     "shell.execute_reply": "2025-09-21T09:53:52.671309Z",
     "shell.execute_reply.started": "2025-09-21T09:53:52.637029Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Dataset\n",
    "img_to_augment = random.choices(train_df[\"Image_name\"].to_list(), k=int(len(train_df) * 0.3))\n",
    "\n",
    "simpleaugment = SimpleAugment(p=1, keys=img_to_augment)\n",
    "\n",
    "train_set = XRayDataset(train_df, train=True, transform=simpleaugment)\n",
    "val_set = XRayDataset(val_df, train=True)\n",
    "test_set = XRayDataset(submission_df, train=False)\n",
    "\n",
    "# DataLoader\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(\n",
    "    train_set, \n",
    "    batch_size=batch_size, \n",
    "    shuffle=True, \n",
    "    pin_memory=True,\n",
    "    num_workers=os.cpu_count()\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_set, \n",
    "    batch_size=batch_size, \n",
    "    pin_memory=True,\n",
    "    num_workers=os.cpu_count()\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_set, \n",
    "    batch_size=batch_size, \n",
    "    pin_memory=True,\n",
    "    num_workers=os.cpu_count()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-21T09:53:52.672996Z",
     "iopub.status.busy": "2025-09-21T09:53:52.672788Z",
     "iopub.status.idle": "2025-09-21T09:53:54.183464Z",
     "shell.execute_reply": "2025-09-21T09:53:54.182703Z",
     "shell.execute_reply.started": "2025-09-21T09:53:52.672980Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/convnext_tiny-983f1562.pth\" to /root/.cache/torch/hub/checkpoints/convnext_tiny-983f1562.pth\n",
      "100%|██████████| 109M/109M [00:00<00:00, 201MB/s] \n"
     ]
    }
   ],
   "source": [
    "# Models and functions\n",
    "randm, randt = True, True\n",
    "model_name = \"convnext\"\n",
    "get_model, in_features = models_[model_name]\n",
    "model = get_model(fine_tune=False)\n",
    "observe = True\n",
    "\n",
    "observing_agent = Agent(in_features, len(augmentation_space), not randt, not randm)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "loss_fn = FocalLoss(weights=torch.tensor(class_weights).to(device), reduction=\"none\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-21T09:53:54.184596Z",
     "iopub.status.busy": "2025-09-21T09:53:54.184315Z",
     "iopub.status.idle": "2025-09-21T12:18:19.851864Z",
     "shell.execute_reply": "2025-09-21T12:18:19.851068Z",
     "shell.execute_reply.started": "2025-09-21T09:53:54.184572Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1343/1343 [38:17<00:00,  1.71s/it]\n",
      "Validation: 100%|██████████| 336/336 [08:38<00:00,  1.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best auroc score: 0.8748\n",
      "Epoch 1/3 | Train Loss: 0.4860 | Val Loss: 0.4489 | Acc: 0.8568 | Prec: 0.7364 | Rec: 0.6812 | AUROC: 0.8748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1343/1343 [40:05<00:00,  1.79s/it]\n",
      "Validation: 100%|██████████| 336/336 [08:33<00:00,  1.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best auroc score: 0.8948\n",
      "Epoch 2/3 | Train Loss: 0.4189 | Val Loss: 0.4031 | Acc: 0.8704 | Prec: 0.7719 | Rec: 0.6966 | AUROC: 0.8948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1343/1343 [40:14<00:00,  1.80s/it]\n",
      "Validation: 100%|██████████| 336/336 [08:35<00:00,  1.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best auroc score: 0.8965\n",
      "Epoch 3/3 | Train Loss: 0.3940 | Val Loss: 0.4032 | Acc: 0.8735 | Prec: 0.8017 | Rec: 0.6680 | AUROC: 0.8965\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "r_weight = 0.5\n",
    "r_norm = True\n",
    "model.to(device)\n",
    "observing_agent.to(device)\n",
    "best_score = 0\n",
    "lr_scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "    optimizer,\n",
    "    max_lr=1e-3,\n",
    "    epochs=epochs,\n",
    "    steps_per_epoch=len(train_loader),\n",
    "    pct_start=0.1\n",
    ")\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    # Training\n",
    "    if observe:\n",
    "        handle = _register_head_hook(model)\n",
    "    \n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for keys, imgs, targets in tqdm(train_loader, desc=\"Training\"):\n",
    "        imgs, targets = imgs.to(device, non_blocking=True), targets.to(device, non_blocking=True)\n",
    "\n",
    "        logits = model(imgs)\n",
    "        state = current_state[\"head_input\"]\n",
    "\n",
    "        loss = loss_fn(logits, targets)\n",
    "\n",
    "        prev_loss = observing_agent.loss_memory(keys, loss.detach())\n",
    "        probs = torch.sigmoid(logits)\n",
    "\n",
    "        if randm or randt:\n",
    "    \n",
    "            _, _ = observing_agent(state)\n",
    "            intersection_keys, transform_idx, magnitude =  simpleaugment.get(keys)\n",
    "            observing_agent.set_action(magnitude, transform_idx)\n",
    "    \n",
    "            entropy = torch.sum(probs * torch.log(probs + 1e-8), dim=1).unsqueeze(1)\n",
    "            reward = r_weight * (loss.detach().mean() - prev_loss.mean()) + (1 - r_weight) * entropy\n",
    "            if r_norm:\n",
    "                reward = (reward - reward.mean()) / (reward.std() - 1e-8)\n",
    "    \n",
    "            actor_loss, critic_loss = observing_agent.update(keys, state, reward)\n",
    "            total_actor_loss += actor_loss.item()\n",
    "            total_critic_loss += critic_loss.item()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "    train_loss /= len(train_loader)\n",
    "\n",
    "    # Validation\n",
    "\n",
    "    _remove_head_hook(handle)\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "\n",
    "    all_probs = []\n",
    "    all_targets = []\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        for keys, imgs, targets in tqdm(val_loader, desc=\"Validation\"):\n",
    "            imgs, targets = imgs.to(device, non_blocking=True), targets.to(device, non_blocking=True)\n",
    "\n",
    "            logits = model(imgs)\n",
    "            loss = loss_fn(logits, targets)\n",
    "            probs = torch.sigmoid(logits)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            all_probs.append(probs)\n",
    "            all_targets.append(targets)\n",
    "\n",
    "    val_loss /= len(val_loader)\n",
    "    all_probs = torch.cat(all_probs, dim=0)\n",
    "    all_targets = torch.cat(all_targets, dim=0)\n",
    "\n",
    "    all_preds = (all_probs >= 0.5).int()\n",
    "\n",
    "    val_accuracy = accuracy(all_preds, all_targets.int(), task=\"multilabel\", num_labels=14)\n",
    "    val_precision = precision(all_preds, all_targets.int(), task=\"multilabel\", num_labels=14)\n",
    "    val_recall = recall(all_preds, all_targets.int(), task=\"multilabel\", num_labels=14)\n",
    "    val_auroc = auroc(all_probs, all_targets.int(), task=\"multilabel\", num_labels=14)\n",
    "\n",
    "\n",
    "    if val_auroc > best_score:\n",
    "        best_score = val_auroc\n",
    "        initial_best_model = model.state_dict()\n",
    "        torch.save(initial_best_model, \"initial_best_model.pth\")\n",
    "        print(f\"New best auroc score: {best_score:.4f}\")\n",
    "\n",
    "    print(\n",
    "        f\"Epoch {epoch+1}/{epochs} | \"\n",
    "        f\"Train Loss: {train_loss:.4f} | \"\n",
    "        f\"Actor Loss: {actor_loss:.4f} | \"\n",
    "        f\"Critic Loss: {critic_loss:.4f} | \"\n",
    "        f\"Val Loss: {val_loss:.4f} | \"\n",
    "        f\"Acc: {val_accuracy:.4f} | \"\n",
    "        f\"Prec: {val_precision:.4f} | \"\n",
    "        f\"Rec: {val_recall:.4f} | \"\n",
    "        f\"AUROC: {val_auroc:.4f}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finetuning using AdaAugment and Focal Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Things to try out here:\n",
    "\n",
    "+ Add back the Layernorm after Linear1\n",
    "+ Advantage Norm\n",
    "+ Reward Norm\n",
    "+ Lr scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-21T12:18:19.904494Z",
     "iopub.status.busy": "2025-09-21T12:18:19.904283Z",
     "iopub.status.idle": "2025-09-21T12:18:21.038950Z",
     "shell.execute_reply": "2025-09-21T12:18:21.038197Z",
     "shell.execute_reply.started": "2025-09-21T12:18:19.904463Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "randm, randt = False, False\n",
    "\n",
    "ada_augment=AdaAugment(rand_m=randm, rand_t=randt)\n",
    "train_set = XRayDataset(train_df, train=True, transform=ada_augment)\n",
    "\n",
    "w_ = torch.tensor(train_set.df[\"weight\"], dtype=torch.float32)\n",
    "sampler = torch.utils.data.WeightedRandomSampler(\n",
    "    weights=w_,\n",
    "    num_samples=len(w_),\n",
    "    replacement=True\n",
    ")\n",
    "\n",
    "# New dataset using adaptive augmentations\n",
    "train_loader = DataLoader(\n",
    "    train_set, \n",
    "    batch_size=batch_size,\n",
    "    #sampler=sampler,\n",
    "    shuffle=True, \n",
    "    pin_memory=True,\n",
    "    num_workers=os.cpu_count()\n",
    ")\n",
    "\n",
    "get_model, in_features = models_[model_name]\n",
    "\n",
    "model = get_model(fine_tune=True)\n",
    "\n",
    "model.load_state_dict(torch.load(\"/kaggle/working/initial_best_model.pth\", map_location=device, weights_only=False))\n",
    "\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=1e-5)\n",
    "\n",
    "loss_fn = FocalLoss(weights=torch.tensor(class_weights, dtype=torch.float32), reduction=\"none\")\n",
    "\n",
    "agent = Agent(in_features, len(augmentation_space), not randt, not randm)\n",
    "current_state = {}\n",
    "best_score = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-21T12:18:21.040433Z",
     "iopub.status.busy": "2025-09-21T12:18:21.039831Z",
     "iopub.status.idle": "2025-09-21T17:53:29.365512Z",
     "shell.execute_reply": "2025-09-21T17:53:29.364556Z",
     "shell.execute_reply.started": "2025-09-21T12:18:21.040399Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1343/1343 [33:32<00:00,  1.50s/it]\n",
      "Validation: 100%|██████████| 336/336 [08:34<00:00,  1.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best auroc score: 0.8996\n",
      "Epoch 1/5 | Train Loss: 0.3671 | Actor Loss: -4.2872 |Critic Loss: 3.7018 |Val Loss: 0.3924 | Acc: 0.8760 | Prec: 0.7881 | Rec: 0.7014 | AUROC: 0.8996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1343/1343 [1:03:15<00:00,  2.83s/it]\n",
      "Validation: 100%|██████████| 336/336 [08:38<00:00,  1.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best auroc score: 0.9005\n",
      "Epoch 2/5 | Train Loss: 0.4004 | Actor Loss: 0.3604 |Critic Loss: 65.4283 |Val Loss: 0.3906 | Acc: 0.8759 | Prec: 0.7811 | Rec: 0.7120 | AUROC: 0.9005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1343/1343 [1:05:40<00:00,  2.93s/it]\n",
      "Validation: 100%|██████████| 336/336 [08:42<00:00,  1.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best auroc score: 0.9008\n",
      "Epoch 3/5 | Train Loss: 0.3967 | Actor Loss: -2.9447 |Critic Loss: 56.7383 |Val Loss: 0.3901 | Acc: 0.8762 | Prec: 0.7819 | Rec: 0.7118 | AUROC: 0.9008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1343/1343 [1:04:18<00:00,  2.87s/it]\n",
      "Validation: 100%|██████████| 336/336 [09:01<00:00,  1.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best auroc score: 0.9011\n",
      "Epoch 4/5 | Train Loss: 0.3955 | Actor Loss: -3.6595 |Critic Loss: 152.5614 |Val Loss: 0.3898 | Acc: 0.8763 | Prec: 0.7830 | Rec: 0.7110 | AUROC: 0.9011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1343/1343 [1:04:28<00:00,  2.88s/it]\n",
      "Validation: 100%|██████████| 336/336 [08:53<00:00,  1.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best auroc score: 0.9013\n",
      "Epoch 5/5 | Train Loss: 0.3936 | Actor Loss: -2.8835 |Critic Loss: 222.7858 |Val Loss: 0.3896 | Acc: 0.8763 | Prec: 0.7825 | Rec: 0.7116 | AUROC: 0.9013\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "r_weight = 1.0\n",
    "r_norm = True\n",
    "model.to(device)\n",
    "agent.to(device)\n",
    "\n",
    "    \n",
    "for epoch in range(epochs):\n",
    "    # Training\n",
    "    \n",
    "    model.train()\n",
    "    handle = _register_head_hook(model)\n",
    "    \n",
    "    train_loss, total_actor_loss, total_critic_loss = 0, 0, 0\n",
    "    for keys, imgs, targets in tqdm(train_loader, desc=\"Training\"):\n",
    "        imgs, targets = imgs.to(device, non_blocking=True), targets.to(device, non_blocking=True)\n",
    "\n",
    "        logits = model(imgs)\n",
    "        state = current_state[\"head_input\"]\n",
    "\n",
    "        loss = loss_fn(logits, targets)\n",
    "\n",
    "        prev_loss = agent.loss_memory(keys, loss.detach())\n",
    "        probs = torch.sigmoid(logits)\n",
    "\n",
    "        if randm or randt:\n",
    "    \n",
    "            action, transform_idx = agent(state)\n",
    "            ada_augment.set(keys, action, transform_idx)\n",
    "    \n",
    "            entropy = torch.sum(probs * torch.log(probs + 1e-8), dim=1).unsqueeze(1)\n",
    "            reward = r_weight * (loss.detach().mean() - prev_loss.mean()) + (1 - r_weight) * entropy\n",
    "            if r_norm:\n",
    "                reward = (reward - reward.mean()) / (reward.std() - 1e-8)\n",
    "    \n",
    "            actor_loss, critic_loss = agent.update(keys, state, reward)\n",
    "            total_actor_loss += actor_loss.item()\n",
    "            total_critic_loss += critic_loss.item()\n",
    "\n",
    "        loss = loss.mean()\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    train_loss /= len(train_loader)\n",
    "    total_actor_loss /= len(train_loader)\n",
    "    total_critic_loss /= len(train_loader)\n",
    "\n",
    "    _remove_head_hook(handle)\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "\n",
    "    all_probs = []\n",
    "    all_targets = []\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        for keys, imgs, targets in tqdm(val_loader, desc=\"Validation\"):\n",
    "            imgs, targets = imgs.to(device, non_blocking=True), targets.to(device, non_blocking=True)\n",
    "\n",
    "            logits = model(imgs)\n",
    "            loss = loss_fn(logits, targets)\n",
    "            loss = loss.mean()\n",
    "            probs = torch.sigmoid(logits)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            all_probs.append(probs)\n",
    "            all_targets.append(targets)\n",
    "\n",
    "    val_loss /= len(val_loader)\n",
    "    all_probs = torch.cat(all_probs, dim=0)\n",
    "    all_targets = torch.cat(all_targets, dim=0)\n",
    "\n",
    "    all_preds = (all_probs >= 0.5).int()\n",
    "\n",
    "    val_accuracy = accuracy(all_preds, all_targets.int(), task=\"multilabel\", num_labels=14)\n",
    "    val_precision = precision(all_preds, all_targets.int(), task=\"multilabel\", num_labels=14)\n",
    "    val_recall = recall(all_preds, all_targets.int(), task=\"multilabel\", num_labels=14)\n",
    "    val_auroc = auroc(all_probs, all_targets.int(), task=\"multilabel\", num_labels=14)\n",
    "\n",
    "    if val_auroc > best_score:\n",
    "        best_score = val_auroc\n",
    "        initial_best_model = model.state_dict()\n",
    "        torch.save(initial_best_model, \"best_model.pth\")\n",
    "        print(f\"New best auroc score: {best_score:.4f}\")\n",
    "\n",
    "    print(\n",
    "        f\"Epoch {epoch+1}/{epochs} | \"\n",
    "        f\"Train Loss: {train_loss:.4f} | \"\n",
    "        f\"Actor Loss: {total_actor_loss:.4f} | \"\n",
    "        f\"Critic Loss: {total_critic_loss:.4f} | \"\n",
    "        f\"Val Loss: {val_loss:.4f} | \"\n",
    "        f\"Acc: {val_accuracy:.4f} | \"\n",
    "        f\"Prec: {val_precision:.4f} | \"\n",
    "        f\"Rec: {val_recall:.4f} | \"\n",
    "        f\"AUROC: {val_auroc:.4f}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-21T18:17:17.286758Z",
     "iopub.status.busy": "2025-09-21T18:17:17.286402Z",
     "iopub.status.idle": "2025-09-21T18:17:17.292845Z",
     "shell.execute_reply": "2025-09-21T18:17:17.292162Z",
     "shell.execute_reply.started": "2025-09-21T18:17:17.286726Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def create_submission(model_name=model_name):\n",
    "    get_model, _ = models_[model_name]\n",
    "    model = get_model()\n",
    "    model.load_state_dict(torch.load(\"/kaggle/working/best_model.pth\", map_location=device, weights_only=False))\n",
    "\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    all_keys = []\n",
    "    all_probs = []\n",
    "    \n",
    "    with torch.inference_mode():\n",
    "        for key, img in tqdm(test_loader):\n",
    "            img = img.to(device)\n",
    "\n",
    "            out = model(img)\n",
    "            probs = torch.sigmoid(out)\n",
    "\n",
    "            all_keys.extend(key)\n",
    "            all_probs.append(probs.cpu().numpy())\n",
    "            \n",
    "    all_probs = np.concatenate(all_probs, axis=0)\n",
    "\n",
    "    return all_keys, all_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-21T18:17:18.856273Z",
     "iopub.status.busy": "2025-09-21T18:17:18.855664Z",
     "iopub.status.idle": "2025-09-21T18:34:47.482657Z",
     "shell.execute_reply": "2025-09-21T18:34:47.481903Z",
     "shell.execute_reply.started": "2025-09-21T18:17:18.856249Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 723/723 [17:26<00:00,  1.45s/it]\n"
     ]
    }
   ],
   "source": [
    "all_keys, all_probs = create_submission()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-21T18:56:30.805602Z",
     "iopub.status.busy": "2025-09-21T18:56:30.804934Z",
     "iopub.status.idle": "2025-09-21T18:56:31.423776Z",
     "shell.execute_reply": "2025-09-21T18:56:31.423016Z",
     "shell.execute_reply.started": "2025-09-21T18:56:30.805575Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Final submission file created at /kaggle/working/submission.csv\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.5\n",
    "binary_ = False\n",
    "final_submission = pd.DataFrame()\n",
    "final_submission[\"Image_name\"] = all_keys\n",
    "if binary_:\n",
    "    final_submission[label_columns] = (probs_ > threshold).astype(int)\n",
    "else:\n",
    "    final_submission[label_columns] = probs_\n",
    "final_submission.to_csv('/kaggle/working/submission.csv', index=False)\n",
    "\n",
    "print(\"=\"* 70)\n",
    "print(\"Final submission file created at /kaggle/working/submission.csv\")\n",
    "print(\"=\"* 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-21T18:56:33.758942Z",
     "iopub.status.busy": "2025-09-21T18:56:33.758674Z",
     "iopub.status.idle": "2025-09-21T18:56:33.870308Z",
     "shell.execute_reply": "2025-09-21T18:56:33.869599Z",
     "shell.execute_reply.started": "2025-09-21T18:56:33.758923Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image_name</th>\n",
       "      <th>Atelectasis</th>\n",
       "      <th>Cardiomegaly</th>\n",
       "      <th>Consolidation</th>\n",
       "      <th>Edema</th>\n",
       "      <th>Enlarged Cardiomediastinum</th>\n",
       "      <th>Fracture</th>\n",
       "      <th>Lung Lesion</th>\n",
       "      <th>Lung Opacity</th>\n",
       "      <th>No Finding</th>\n",
       "      <th>Pleural Effusion</th>\n",
       "      <th>Pleural Other</th>\n",
       "      <th>Pneumonia</th>\n",
       "      <th>Pneumothorax</th>\n",
       "      <th>Support Devices</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00000005_001_001.jpg</td>\n",
       "      <td>0.220297</td>\n",
       "      <td>0.149363</td>\n",
       "      <td>0.195031</td>\n",
       "      <td>0.123469</td>\n",
       "      <td>0.210709</td>\n",
       "      <td>0.305022</td>\n",
       "      <td>0.233154</td>\n",
       "      <td>0.258701</td>\n",
       "      <td>0.529039</td>\n",
       "      <td>0.193854</td>\n",
       "      <td>0.235400</td>\n",
       "      <td>0.223850</td>\n",
       "      <td>0.256924</td>\n",
       "      <td>0.454828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00000005_001_002.jpg</td>\n",
       "      <td>0.225101</td>\n",
       "      <td>0.214264</td>\n",
       "      <td>0.214019</td>\n",
       "      <td>0.186304</td>\n",
       "      <td>0.278467</td>\n",
       "      <td>0.276405</td>\n",
       "      <td>0.255477</td>\n",
       "      <td>0.275641</td>\n",
       "      <td>0.379550</td>\n",
       "      <td>0.217344</td>\n",
       "      <td>0.197508</td>\n",
       "      <td>0.234026</td>\n",
       "      <td>0.256407</td>\n",
       "      <td>0.632703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00000005_002_001.jpg</td>\n",
       "      <td>0.720314</td>\n",
       "      <td>0.549541</td>\n",
       "      <td>0.610916</td>\n",
       "      <td>0.405752</td>\n",
       "      <td>0.676551</td>\n",
       "      <td>0.461761</td>\n",
       "      <td>0.292920</td>\n",
       "      <td>0.745153</td>\n",
       "      <td>0.107114</td>\n",
       "      <td>0.633497</td>\n",
       "      <td>0.239078</td>\n",
       "      <td>0.392544</td>\n",
       "      <td>0.475623</td>\n",
       "      <td>0.698820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00000005_002_002.jpg</td>\n",
       "      <td>0.691454</td>\n",
       "      <td>0.401686</td>\n",
       "      <td>0.602385</td>\n",
       "      <td>0.266316</td>\n",
       "      <td>0.526638</td>\n",
       "      <td>0.593861</td>\n",
       "      <td>0.363133</td>\n",
       "      <td>0.690712</td>\n",
       "      <td>0.113465</td>\n",
       "      <td>0.611649</td>\n",
       "      <td>0.352090</td>\n",
       "      <td>0.489921</td>\n",
       "      <td>0.658006</td>\n",
       "      <td>0.696855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00000007_001_001.jpg</td>\n",
       "      <td>0.586692</td>\n",
       "      <td>0.623392</td>\n",
       "      <td>0.428747</td>\n",
       "      <td>0.492691</td>\n",
       "      <td>0.694068</td>\n",
       "      <td>0.263567</td>\n",
       "      <td>0.216696</td>\n",
       "      <td>0.654815</td>\n",
       "      <td>0.174051</td>\n",
       "      <td>0.480549</td>\n",
       "      <td>0.145823</td>\n",
       "      <td>0.236672</td>\n",
       "      <td>0.230011</td>\n",
       "      <td>0.654003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46228</th>\n",
       "      <td>20009235_000_000.jpg</td>\n",
       "      <td>0.275094</td>\n",
       "      <td>0.163307</td>\n",
       "      <td>0.203308</td>\n",
       "      <td>0.161742</td>\n",
       "      <td>0.098608</td>\n",
       "      <td>0.082475</td>\n",
       "      <td>0.346820</td>\n",
       "      <td>0.349803</td>\n",
       "      <td>0.513322</td>\n",
       "      <td>0.266759</td>\n",
       "      <td>0.206782</td>\n",
       "      <td>0.154588</td>\n",
       "      <td>0.200309</td>\n",
       "      <td>0.085841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46229</th>\n",
       "      <td>20009236_000_000.jpg</td>\n",
       "      <td>0.205679</td>\n",
       "      <td>0.128511</td>\n",
       "      <td>0.131184</td>\n",
       "      <td>0.098202</td>\n",
       "      <td>0.087050</td>\n",
       "      <td>0.080408</td>\n",
       "      <td>0.279345</td>\n",
       "      <td>0.292245</td>\n",
       "      <td>0.639288</td>\n",
       "      <td>0.140768</td>\n",
       "      <td>0.156294</td>\n",
       "      <td>0.128068</td>\n",
       "      <td>0.126906</td>\n",
       "      <td>0.079985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46230</th>\n",
       "      <td>20009238_000_000.jpg</td>\n",
       "      <td>0.199245</td>\n",
       "      <td>0.130255</td>\n",
       "      <td>0.133074</td>\n",
       "      <td>0.102610</td>\n",
       "      <td>0.093344</td>\n",
       "      <td>0.076683</td>\n",
       "      <td>0.273192</td>\n",
       "      <td>0.301521</td>\n",
       "      <td>0.619003</td>\n",
       "      <td>0.157510</td>\n",
       "      <td>0.168086</td>\n",
       "      <td>0.113717</td>\n",
       "      <td>0.146211</td>\n",
       "      <td>0.091032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46231</th>\n",
       "      <td>20009240_000_000.jpg</td>\n",
       "      <td>0.346170</td>\n",
       "      <td>0.223896</td>\n",
       "      <td>0.176529</td>\n",
       "      <td>0.144243</td>\n",
       "      <td>0.143350</td>\n",
       "      <td>0.093923</td>\n",
       "      <td>0.204498</td>\n",
       "      <td>0.346055</td>\n",
       "      <td>0.581372</td>\n",
       "      <td>0.239030</td>\n",
       "      <td>0.141905</td>\n",
       "      <td>0.142443</td>\n",
       "      <td>0.108583</td>\n",
       "      <td>0.116798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46232</th>\n",
       "      <td>20009241_000_000.jpg</td>\n",
       "      <td>0.273891</td>\n",
       "      <td>0.206595</td>\n",
       "      <td>0.170680</td>\n",
       "      <td>0.164306</td>\n",
       "      <td>0.124686</td>\n",
       "      <td>0.086882</td>\n",
       "      <td>0.266800</td>\n",
       "      <td>0.337728</td>\n",
       "      <td>0.552777</td>\n",
       "      <td>0.243443</td>\n",
       "      <td>0.190540</td>\n",
       "      <td>0.139593</td>\n",
       "      <td>0.133007</td>\n",
       "      <td>0.093387</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>46233 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Image_name  Atelectasis  Cardiomegaly  Consolidation  \\\n",
       "0      00000005_001_001.jpg     0.220297      0.149363       0.195031   \n",
       "1      00000005_001_002.jpg     0.225101      0.214264       0.214019   \n",
       "2      00000005_002_001.jpg     0.720314      0.549541       0.610916   \n",
       "3      00000005_002_002.jpg     0.691454      0.401686       0.602385   \n",
       "4      00000007_001_001.jpg     0.586692      0.623392       0.428747   \n",
       "...                     ...          ...           ...            ...   \n",
       "46228  20009235_000_000.jpg     0.275094      0.163307       0.203308   \n",
       "46229  20009236_000_000.jpg     0.205679      0.128511       0.131184   \n",
       "46230  20009238_000_000.jpg     0.199245      0.130255       0.133074   \n",
       "46231  20009240_000_000.jpg     0.346170      0.223896       0.176529   \n",
       "46232  20009241_000_000.jpg     0.273891      0.206595       0.170680   \n",
       "\n",
       "          Edema  Enlarged Cardiomediastinum  Fracture  Lung Lesion  \\\n",
       "0      0.123469                    0.210709  0.305022     0.233154   \n",
       "1      0.186304                    0.278467  0.276405     0.255477   \n",
       "2      0.405752                    0.676551  0.461761     0.292920   \n",
       "3      0.266316                    0.526638  0.593861     0.363133   \n",
       "4      0.492691                    0.694068  0.263567     0.216696   \n",
       "...         ...                         ...       ...          ...   \n",
       "46228  0.161742                    0.098608  0.082475     0.346820   \n",
       "46229  0.098202                    0.087050  0.080408     0.279345   \n",
       "46230  0.102610                    0.093344  0.076683     0.273192   \n",
       "46231  0.144243                    0.143350  0.093923     0.204498   \n",
       "46232  0.164306                    0.124686  0.086882     0.266800   \n",
       "\n",
       "       Lung Opacity  No Finding  Pleural Effusion  Pleural Other  Pneumonia  \\\n",
       "0          0.258701    0.529039          0.193854       0.235400   0.223850   \n",
       "1          0.275641    0.379550          0.217344       0.197508   0.234026   \n",
       "2          0.745153    0.107114          0.633497       0.239078   0.392544   \n",
       "3          0.690712    0.113465          0.611649       0.352090   0.489921   \n",
       "4          0.654815    0.174051          0.480549       0.145823   0.236672   \n",
       "...             ...         ...               ...            ...        ...   \n",
       "46228      0.349803    0.513322          0.266759       0.206782   0.154588   \n",
       "46229      0.292245    0.639288          0.140768       0.156294   0.128068   \n",
       "46230      0.301521    0.619003          0.157510       0.168086   0.113717   \n",
       "46231      0.346055    0.581372          0.239030       0.141905   0.142443   \n",
       "46232      0.337728    0.552777          0.243443       0.190540   0.139593   \n",
       "\n",
       "       Pneumothorax  Support Devices  \n",
       "0          0.256924         0.454828  \n",
       "1          0.256407         0.632703  \n",
       "2          0.475623         0.698820  \n",
       "3          0.658006         0.696855  \n",
       "4          0.230011         0.654003  \n",
       "...             ...              ...  \n",
       "46228      0.200309         0.085841  \n",
       "46229      0.126906         0.079985  \n",
       "46230      0.146211         0.091032  \n",
       "46231      0.108583         0.116798  \n",
       "46232      0.133007         0.093387  \n",
       "\n",
       "[46233 rows x 15 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"/kaggle/working/submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 13449579,
     "sourceId": 112899,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
