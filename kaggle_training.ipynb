{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":112899,"databundleVersionId":13449579,"sourceType":"competition"}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torchvision import models, transforms\nfrom torchmetrics.functional import accuracy, recall, precision, auroc\nfrom torch.utils.data import Dataset, DataLoader\nimport timm\nimport numpy as np\nimport pandas as pd\nimport random\nfrom typing import List\nfrom tqdm import tqdm\nfrom torchmetrics.functional import accuracy, recall, precision, auroc\nfrom PIL import Image, ImageEnhance, ImageOps, ImageFilter\nimport os\nfrom glob import glob\nfrom sklearn.model_selection import train_test_split\n\nBASE_DIR = \"/kaggle/input/grand-xray-slam-division-a\"\nlabel_columns = [\n    'Atelectasis', 'Cardiomegaly', 'Consolidation', 'Edema', 'Enlarged Cardiomediastinum',\n    'Fracture', 'Lung Lesion', 'Lung Opacity', 'No Finding', 'Pleural Effusion',\n    'Pleural Other', 'Pneumonia', 'Pneumothorax', 'Support Devices'\n]\n\n\ndef setup_seed(seed=None):\n    if seed is None:\n        return\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    np.random.seed(seed)\n    random.seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"execution":{"iopub.status.busy":"2025-09-20T19:44:37.901080Z","iopub.execute_input":"2025-09-20T19:44:37.901268Z","iopub.status.idle":"2025-09-20T19:44:54.286110Z","shell.execute_reply.started":"2025-09-20T19:44:37.901250Z","shell.execute_reply":"2025-09-20T19:44:54.285464Z"},"trusted":true},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"### Augmentation Spaces and Utilities","metadata":{}},{"cell_type":"code","source":"# used to freeze layers in a model\ndef freeze_all(model):\n    for param in model.parameters():\n        param.requires_grad=False\n\ndef get_resnet18(num_classes=14, fine_tune=True):\n    model = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n\n    if fine_tune:\n        freeze_all(model)\n        for param in model.layer4.parameters():\n            param.requires_grad = True\n\n    model.fc = nn.Linear(512, num_classes)\n    return model\n\ndef get_resnet34(num_classes=14, fine_tune=True):\n    model = models.resnet34(weights=models.ResNet34_Weights.IMAGENET1K_V1)\n\n    if fine_tune:\n        freeze_all(model)\n        for param in model.layer4.parameters():\n            param.requires_grad = True\n\n    model.fc = nn.Linear(512, num_classes)\n    return model\n\ndef get_effnetb0(num_classes=14, fine_tune=True):\n    model = models.efficientnet_b0(weights=models.EfficientNet_B0_Weights.IMAGENET1K_V1)\n\n    if fine_tune:\n        freeze_all(model)\n        for idx in range(6, 8):\n            for param in model.features[idx].parameters():\n                param.requires_grad = True\n\n    model.classifier = nn.Sequential(\n        nn.Dropout(p=0.2, inplace=True),\n        nn.Linear(in_features=1280, out_features=num_classes)\n    )\n    \n    return model\n\ndef get_convnext_tiny(num_classes=14, fine_tune=True):\n    model = models.convnext_tiny(weights=models.ConvNeXt_Tiny_Weights.IMAGENET1K_V1)\n\n    if fine_tune:\n        freeze_all(model)\n        for param in model.features[6].parameters():\n            param.requires_grad = True\n\n    model.classifier[2] = nn.Linear(in_features=768, out_features=num_classes)\n    return model\n\n# returns getter function and number of in features of the classifier\nmodels_ = {\n    \"res18\": (get_resnet18, 512),\n    \"res34\": (get_resnet34, 512),\n    \"effb0\": (get_effnetb0, 1280),\n    \"convnext\" : (get_convnext_tiny, 768),\n}","metadata":{"execution":{"iopub.status.busy":"2025-09-20T19:44:54.287458Z","iopub.execute_input":"2025-09-20T19:44:54.287954Z","iopub.status.idle":"2025-09-20T19:44:54.297031Z","shell.execute_reply.started":"2025-09-20T19:44:54.287929Z","shell.execute_reply":"2025-09-20T19:44:54.296294Z"},"trusted":true},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# Set up transforms\nbasic_transforms = transforms.Compose([\n    transforms.Resize((224, 224)), # resize to 224x224\n    transforms.ToTensor(), # convert to tensor [0,1]\n    transforms.Normalize( # normalize with ImageNet stats\n        mean=[0.485, 0.456, 0.406],\n        std=[0.229, 0.224, 0.225]\n    )\n])\n\n# custom transforms with adaptive magnitude\ndef shear_x(img, magnitude):\n    level = magnitude * 0.3 * random.choice([-1, 1])\n    return img.transform(img.size, Image.AFFINE, (1, level, 0, 0, 1, 0))\n\ndef shear_y(img, magnitude):\n    level = magnitude * 0.3 * random.choice([-1, 1])\n    return img.transform(img.size, Image.AFFINE, (1, 0, 0, level, 1, 0))\n\ndef translate_x(img, magnitude):\n    max_shift = 0.3 * img.size[0]\n    level = magnitude * max_shift * random.choice([-1, 1])\n    return img.transform(img.size, Image.AFFINE, (1, 0, level, 0, 1, 0))\n\ndef translate_y(img, magnitude):\n    max_shift = 0.3 * img.size[1]\n    level = magnitude * max_shift * random.choice([-1, 1])\n    return img.transform(img.size, Image.AFFINE, (1, 0, 0, 0, 1, level))\n\ndef rotate(img, magnitude):\n    degrees = magnitude * 30 * random.choice([-1, 1])\n    return img.rotate(degrees)\n\ndef contrast(img, magnitude):\n    enhancer = ImageEnhance.Contrast(img)\n    factor = 1.0 + (magnitude * random.choice([-0.9, 0.9]))\n    return enhancer.enhance(factor)\n\ndef brightness(img, magnitude):\n    enhancer = ImageEnhance.Brightness(img)\n    factor = 1.0 + (magnitude * random.choice([-0.9, 0.9]))\n    return enhancer.enhance(factor)\n\ndef sharpness(img, magnitude):\n    enhancer = ImageEnhance.Sharpness(img)\n    factor = 1.0 + (magnitude * random.choice([-0.9, 0.9]))\n    return enhancer.enhance(factor)\n\ndef equalize(img, magnitude=None):\n    return ImageOps.equalize(img)\n\ndef gaussian_blur(img, magnitude):\n    radius = magnitude * 2\n    return img.filter(ImageFilter.GaussianBlur(radius))\n\ndef identity(img, magnitude=None):\n    return img\n\naugmentation_space = [\n    shear_x, shear_y, \n    translate_x, translate_y,\n    rotate, equalize, \n    contrast, brightness, \n    sharpness, identity\n]","metadata":{"execution":{"iopub.status.busy":"2025-09-20T19:44:54.297836Z","iopub.execute_input":"2025-09-20T19:44:54.298102Z","iopub.status.idle":"2025-09-20T19:44:54.319600Z","shell.execute_reply.started":"2025-09-20T19:44:54.298080Z","shell.execute_reply":"2025-09-20T19:44:54.318852Z"},"trusted":true},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# AdaAugment can be used to control augmentation magnitudes and operations\n\n\nclass AdaAugment:\n\n    def __init__(self, rand_m, rand_t):\n        self.key_transform = {}\n        self.key_magnitude = {}\n        self.transforms = [\n            shear_x, shear_y, \n            translate_x, translate_y,\n            rotate, equalize, \n            contrast, brightness, \n            sharpness, identity\n        ]\n        self.rand_m = rand_m\n        self.rand_t = rand_t\n\n    def set(self, keys, m=None, transform_idx=None):\n        if m is not None:\n            for i, key in enumerate(keys):\n                self.key_magnitude[key] = m[i].cpu().detach()\n            \n        if transform_idx is not None:\n            for i, key in enumerate(keys):\n                self.key_transform[key] = transform_idx[i].cpu().detach()\n    \n    def __call__(self, key, img):\n        \"\"\"\n        Apply an augmentation to the image based on stored magnitudes and transforms.\n        \n        Args:\n            key: unique identifier for the sample\n            img: input image to transform\n    \n        Returns:\n            Augmented image\n        \"\"\"\n        # --- Determine magnitude ---\n        magnitude = self.key_magnitude.get(key)\n        \n        if magnitude is None:\n            # No stored magnitude\n            if self.rand_m:\n                # Random magnitude\n                if random.random() < 0.4:\n                    return img  # skip transform 40% of the time\n                magnitude = random.random()\n            else:\n                magnitude = 0.0\n        else:\n            # Magnitude exists\n            if not self.rand_m and not self.rand_t:\n                # Use magnitude corresponding to stored transform index\n                transform_idx = int(self.key_transform.get(key))\n                if isinstance(magnitude, (list, torch.Tensor)):\n                    magnitude = float(magnitude[transform_idx])\n                else:\n                    magnitude = float(magnitude)\n            else:\n                magnitude = float(magnitude)\n    \n        # --- Determine transform ---\n        transform_idx = self.key_transform.get(key)\n        \n        if transform_idx is None:\n            # No stored transform\n            transform = random.choice(self.transforms) if self.rand_t else self.transforms[-1]\n        else:\n            transform = self.transforms[int(transform_idx)]\n    \n        # --- Apply transform ---\n        return transform(img, magnitude)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-20T19:44:54.321314Z","iopub.execute_input":"2025-09-20T19:44:54.321520Z","iopub.status.idle":"2025-09-20T19:44:54.339037Z","shell.execute_reply.started":"2025-09-20T19:44:54.321496Z","shell.execute_reply":"2025-09-20T19:44:54.338511Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# Focal Loss for fine tuninng\n\nclass FocalLoss(nn.Module):\n\n    def __init__(self, weights:List=None, gamma=2.0, reduction=\"mean\"):\n        super().__init__()\n\n        self.weights = weights.to(device)\n        self.gamma = gamma\n        self.reduction = reduction\n\n    def forward(self, logit, target):\n        bce_loss = nn.functional.binary_cross_entropy_with_logits(\n            logit, target,\n            reduction=\"none\"\n        )\n        probs = torch.exp(-bce_loss)\n        F_loss = self.weights.to(target.device) * (1-probs) ** self.gamma * bce_loss\n\n        if self.reduction == \"mean\":\n            return F_loss.mean()\n        elif self.reduction == \"none\":\n            return F_loss   \n        else:\n            return F_loss.sum()","metadata":{"execution":{"iopub.status.busy":"2025-09-20T19:44:54.339840Z","iopub.execute_input":"2025-09-20T19:44:54.340119Z","iopub.status.idle":"2025-09-20T19:44:54.353914Z","shell.execute_reply.started":"2025-09-20T19:44:54.340093Z","shell.execute_reply":"2025-09-20T19:44:54.353296Z"},"trusted":true},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# Saves per sample information such as previous loss etc.\n\nclass ValueMemory:\n    def __init__(self):\n        \"\"\"\n        Stores the last value per key (no EMA).\n        \"\"\"\n        self.values = {}\n\n    def __call__(self, keys, vals):\n        \"\"\"\n        keys: list of sample identifiers\n        vals: torch.Tensor of shape (len(keys), D)\n        Returns: current stored values, previous stored values\n        \"\"\"\n        stored_list = []\n        new_list = []\n\n        for i, key in enumerate(keys):\n            val = vals[i]\n            if key not in self.values:\n                old = val.clone()  # nothing stored yet → use current\n            else:\n                old = self.values[key]\n\n            self.values[key] = val  # overwrite with last value\n\n            stored_list.append(old.unsqueeze(0))\n            new_list.append(self.values[key].unsqueeze(0))\n\n        stored = torch.cat(stored_list, dim=0)  # previous values\n        return stored\n\n    def get(self, key):\n        \"\"\"\n        Access the stored value for a single key\n        \"\"\"\n        return self.values.get(key, None)\n\n    def get_multi(self, keys):\n        \"\"\"\n        Access stored values for multiple keys\n        \"\"\"\n        return torch.stack([self.values[k] for k in keys])","metadata":{"execution":{"iopub.status.busy":"2025-09-20T19:44:54.354505Z","iopub.execute_input":"2025-09-20T19:44:54.354703Z","iopub.status.idle":"2025-09-20T19:44:54.374397Z","shell.execute_reply.started":"2025-09-20T19:44:54.354687Z","shell.execute_reply":"2025-09-20T19:44:54.373755Z"},"trusted":true},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"### Setting up the AdaAugment Agent\n+ Critic => returns value for a state\n+ Actor => Parameterizes a beta distribution that is used to sample augmentation magnitudes\n+ Controller => Parameterizes a categorical distribution that is used to sample transformations from the augmentation space","metadata":{}},{"cell_type":"code","source":"class Actor(nn.Module):\n    def __init__(self, in_features, hidden, out_features):\n        super().__init__()\n        self.linear1 = nn.Linear(in_features, hidden)\n        #self.layernorm1 = nn.LayerNorm(hidden)\n        self.linear2 = nn.Linear(hidden, hidden)\n        #self.layernorm2 = nn.LayerNorm(hidden)\n        self.alpha_head = nn.Linear(hidden, out_features)\n        self.beta_head = nn.Linear(hidden, out_features)\n\n    def forward(self, x):\n        x = torch.relu(self.linear1(x))\n        x = torch.relu(self.linear2(x))\n        return torch.softmax(self.alpha_head(x), dim=-1) + 1, torch.softmax(self.beta_head(x), dim=-1) + 1\n\n    def get_dist(self, x):\n        alpha, beta = self(x)\n        dist = torch.distributions.Beta(alpha, beta)\n        return dist\n\n\nclass Critic(nn.Module):\n\n    def __init__(self, in_features, hidden):\n        super().__init__()\n        self.linear1 = nn.Linear(in_features, hidden)\n        #self.layernorm1 = nn.LayerNorm(hidden)\n        self.linear2 = nn.Linear(hidden, hidden)\n        #self.layernorm2 = nn.LayerNorm(hidden)\n        self.head = nn.Linear(hidden, 1)\n\n    def forward(self, x):\n        x = torch.relu(self.linear1(x))\n        x = torch.relu(self.linear2(x))\n        x = self.head(x)\n        return x\n\n\nclass Controller(nn.Module):\n\n    def __init__(self, in_features, hidden):\n        super().__init__()\n        self.linear1 = nn.Linear(in_features, hidden)\n        #self.layernorm1 = nn.LayerNorm(hidden)\n        self.linear2 = nn.Linear(hidden, hidden)\n        #self.layernorm2 = nn.LayerNorm(hidden)\n        self.head = nn.Linear(hidden, len(augmentation_space))\n\n    def forward(self, x):\n        x = torch.relu(self.linear1(x))\n        x = torch.relu(self.linear2(x))\n        x = self.head(x)\n        return x\n    \n    def get_dist(self, x):\n        out = self(x)\n        dist = torch.distributions.Categorical(logits=out)\n        return dist\n\n\nclass Agent(nn.Module):\n\n    def __init__(self, in_features, out_features, control=False, actor=False):\n        super().__init__()\n        self.val_memory = ValueMemory()\n        self.loss_memory = ValueMemory()\n\n        self.critic = Critic(in_features=in_features, hidden=128)\n\n        self.store_ = {}\n\n        self.control_ = control\n        self.actor_ = actor\n        if control:\n            self.controller = Controller(in_features=in_features, hidden=128)\n            self.controller_optimizer = torch.optim.Adam(\n                params=self.controller.parameters(), lr=3e-5, weight_decay=5e-4\n            )\n\n        if actor:\n            self.actor = Actor(in_features=in_features, hidden=128, out_features=out_features) \n\n            self.actor_optimizer = torch.optim.Adam(\n                params=self.actor.parameters(), lr=3e-5, weight_decay=5e-4\n            )\n        self.critic_optimizer = torch.optim.Adam(\n            params=self.critic.parameters(), lr=3e-5, weight_decay=5e-4\n        )\n\n    def forward(self, state):\n        action_actor = None\n        action_controller = None\n\n        if self.actor_:  \n            dist = self.actor.get_dist(state.detach())\n            action_actor = dist.sample()\n            self.store_[\"action_actor\"] = action_actor\n            self.store_[\"dist_actor\"] = dist\n\n        if self.control_:\n            dist = self.controller.get_dist(state.detach())\n            action_controller = dist.sample()\n            self.store_[\"action_controller\"] = action_controller\n            self.store_[\"dist_controller\"] = dist\n\n        return action_actor, action_controller\n\n    def update(self, key, state, reward):\n        value = self.critic(state)\n        prev_state = self.val_memory(key, state)\n        prev_value = self.critic(prev_state)\n        \n        with torch.no_grad():\n            td_target = reward + 0.99 * value\n\n        if self.actor_ and self.control_:\n            dist_actor, action_actor = self.store_[\"dist_actor\"], self.store_[\"action_actor\"]\n            dist_control, action_control = self.store_[\"dist_controller\"], self.store_[\"action_controller\"]\n        \n            # Select magnitude corresponding to the chosen augmentation\n            chosen_magnitude = action_actor.gather(1, action_control.unsqueeze(1))  # shape [B, 1]\n\n            # Controller chooses augmentation index\n            aug_idx = action_control.unsqueeze(1)  # shape [B, 1]\n            \n            # Select alpha, beta for chosen augmentation\n            alpha_chosen = dist_actor.concentration1.gather(1, aug_idx)\n            beta_chosen  = dist_actor.concentration0.gather(1, aug_idx)\n            \n            # Build a Beta distribution only for the chosen augmentation\n            dist_chosen = torch.distributions.Beta(alpha_chosen.squeeze(1), beta_chosen.squeeze(1))\n            \n            # Compute log_prob of chosen magnitude\n            log_prob_actor = dist_chosen.log_prob(chosen_magnitude.squeeze(1))\n        \n            # Log-prob for augmentation choice\n            log_prob_control = dist_control.log_prob(action_control)\n        \n            # Total log prob\n            log_prob = log_prob_actor + log_prob_control\n\n        elif self.actor_:\n            dist, action = self.store_[\"dist_actor\"], self.store_[\"action_actor\"]\n            log_prob = dist.log_prob(action)\n\n        elif self.control_:\n            dist, action = self.store_[\"dist_controller\"], self.store_[\"action_controller\"]\n            log_prob = dist.log_prob(action)\n\n        actor_loss = -(log_prob * (td_target - prev_value.detach())).mean()\n\n        if self.control_:\n            self.controller_optimizer.zero_grad()\n        if self.actor_:\n            self.actor_optimizer.zero_grad()\n        actor_loss.backward()\n        if self.actor_:\n            self.actor_optimizer.step()\n        if self.control_:\n            self.controller_optimizer.step()\n        critic_loss = torch.nn.functional.mse_loss(td_target, prev_value)\n        self.critic_optimizer.zero_grad()\n        critic_loss.backward()\n        self.critic_optimizer.step()\n\n        return actor_loss, critic_loss","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-21T00:01:24.800910Z","iopub.execute_input":"2025-09-21T00:01:24.801263Z","iopub.status.idle":"2025-09-21T00:01:24.819796Z","shell.execute_reply.started":"2025-09-21T00:01:24.801232Z","shell.execute_reply":"2025-09-21T00:01:24.819053Z"}},"outputs":[],"execution_count":130},{"cell_type":"markdown","source":"### Dataset\n+ Class weights\n+ Dataset class","metadata":{}},{"cell_type":"code","source":"def get_class_weights(df):\n    weights = []\n    label_columns = [\n        'Atelectasis', 'Cardiomegaly', 'Consolidation', 'Edema', 'Enlarged Cardiomediastinum',\n        'Fracture', 'Lung Lesion', 'Lung Opacity', 'No Finding', 'Pleural Effusion',\n        'Pleural Other', 'Pneumonia', 'Pneumothorax', 'Support Devices'\n    ]\n\n    for label in label_columns:\n        weight = len(df) / (df[label].sum() + 1e-6)\n        weights.append(weight)\n\n    return weights","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-20T19:44:54.403529Z","iopub.execute_input":"2025-09-20T19:44:54.404245Z","iopub.status.idle":"2025-09-20T19:44:54.426157Z","shell.execute_reply.started":"2025-09-20T19:44:54.404221Z","shell.execute_reply":"2025-09-20T19:44:54.425474Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"class XRayDataset(Dataset):\n\n    def __init__(self, df, train=True, transform=None):\n        super().__init__()\n        self.df = df\n        self.train = train\n        self.transform = transform\n        self.label_columns = [\n            'Atelectasis', 'Cardiomegaly', 'Consolidation', 'Edema', 'Enlarged Cardiomediastinum',\n            'Fracture', 'Lung Lesion', 'Lung Opacity', 'No Finding', 'Pleural Effusion',\n            'Pleural Other', 'Pneumonia', 'Pneumothorax', 'Support Devices'\n        ]\n        if train:\n            class_weights = np.array(get_class_weights(df), dtype=np.float32)\n    \n            sample_weights = (df[label_columns].values.astype(np.float32) * class_weights).mean(axis=1)\n            sample_weights[sample_weights == 0] = 1.0\n            self.df[\"weight\"] = sample_weights\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        img_path = self.df.iloc[idx][\"img_path\"]\n        img = Image.open(img_path).convert(\"RGB\")\n        label = self.df.iloc[idx][self.label_columns].values.astype(np.float32)\n        key = self.df.iloc[idx][\"Image_name\"]\n        \n        if self.train and self.transform is not None:\n            img = self.transform(key, img)\n\n        img = basic_transforms(img)\n\n        if not self.train:\n            return key, img\n\n        return key, img, torch.tensor(label, dtype=torch.float32)","metadata":{"execution":{"iopub.status.busy":"2025-09-20T19:44:54.426885Z","iopub.execute_input":"2025-09-20T19:44:54.427131Z","iopub.status.idle":"2025-09-20T19:44:54.442922Z","shell.execute_reply.started":"2025-09-20T19:44:54.427109Z","shell.execute_reply":"2025-09-20T19:44:54.442276Z"},"trusted":true},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":"### Adapt entire Model to new dataset","metadata":{}},{"cell_type":"code","source":"train_csv = pd.read_csv(\"/kaggle/input/grand-xray-slam-division-a/train1.csv\")\ntrain_csv[\"img_path\"] = train_csv[\"Image_name\"].apply(lambda x: os.path.join(BASE_DIR, \"train1\", x))\nsubmission_df = pd.read_csv(\"/kaggle/input/grand-xray-slam-division-a/sample_submission_1.csv\")\ntrain_df, val_df = train_test_split(\n    train_csv,\n    test_size=0.2,\n    random_state=42,\n    stratify=train_csv[\"No Finding\"]\n)\n\nsubmission_df[\"img_path\"] = submission_df[\"Image_name\"].apply(lambda x : os.path.join(BASE_DIR, \"test1\", x))\nclass_weights = get_class_weights(train_df)\nzipped_class_weights = list(zip(label_columns, class_weights))\n\nfor class_, weight in zipped_class_weights:\n    print(f\"{class_}: {weight:.3f}\\n\")","metadata":{"execution":{"iopub.status.busy":"2025-09-20T19:44:54.444972Z","iopub.execute_input":"2025-09-20T19:44:54.445183Z","iopub.status.idle":"2025-09-20T19:44:55.066418Z","shell.execute_reply.started":"2025-09-20T19:44:54.445168Z","shell.execute_reply":"2025-09-20T19:44:55.065700Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Atelectasis: 2.765\n\nCardiomegaly: 3.073\n\nConsolidation: 3.666\n\nEdema: 4.034\n\nEnlarged Cardiomediastinum: 2.841\n\nFracture: 7.221\n\nLung Lesion: 9.104\n\nLung Opacity: 2.211\n\nNo Finding: 3.162\n\nPleural Effusion: 3.137\n\nPleural Other: 15.225\n\nPneumonia: 7.571\n\nPneumothorax: 12.202\n\nSupport Devices: 2.852\n\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"# Dataset\ntrain_set = XRayDataset(train_df, train=True)\nval_set = XRayDataset(val_df, train=True)\ntest_set = XRayDataset(submission_df, train=False)\n\n# DataLoader\nbatch_size = 64\ntrain_loader = DataLoader(\n    train_set, \n    batch_size=batch_size, \n    shuffle=True, \n    pin_memory=True,\n    num_workers=os.cpu_count()\n)\nval_loader = DataLoader(\n    val_set, \n    batch_size=batch_size, \n    pin_memory=True,\n    num_workers=os.cpu_count()\n)\ntest_loader = DataLoader(\n    test_set, \n    batch_size=batch_size, \n    pin_memory=True,\n    num_workers=os.cpu_count()\n)","metadata":{"execution":{"iopub.status.busy":"2025-09-20T19:44:55.067205Z","iopub.execute_input":"2025-09-20T19:44:55.067474Z","iopub.status.idle":"2025-09-20T19:44:55.092729Z","shell.execute_reply.started":"2025-09-20T19:44:55.067444Z","shell.execute_reply":"2025-09-20T19:44:55.091971Z"},"trusted":true},"outputs":[],"execution_count":11},{"cell_type":"code","source":"# Models and functions\nmodel_name = \"convnext\"\nget_model, in_features = models_[model_name]\nmodel = get_model(fine_tune=False)\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\nloss_fn = FocalLoss(weights=torch.tensor(class_weights).to(device))","metadata":{"execution":{"iopub.status.busy":"2025-09-20T19:46:43.835750Z","iopub.execute_input":"2025-09-20T19:46:43.836329Z","iopub.status.idle":"2025-09-20T19:46:45.081659Z","shell.execute_reply.started":"2025-09-20T19:46:43.836299Z","shell.execute_reply":"2025-09-20T19:46:45.080771Z"},"trusted":true},"outputs":[{"name":"stderr","text":"Downloading: \"https://download.pytorch.org/models/convnext_tiny-983f1562.pth\" to /root/.cache/torch/hub/checkpoints/convnext_tiny-983f1562.pth\n100%|██████████| 109M/109M [00:00<00:00, 210MB/s]  \n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"epochs = 3\nmodel.to(device)\nbest_score = 0\n\nif torch.cuda.device_count() > 1:\n    print(f\"Using {torch.cuda.device_count()} GPUs\")\n    model = nn.DataParallel(model)\n    \nfor epoch in range(epochs):\n    \n    # Training\n    \n    model.train()\n    train_loss = 0\n    for keys, imgs, targets in tqdm(train_loader, desc=\"Training\"):\n        imgs, targets = imgs.to(device, non_blocking=True), targets.to(device, non_blocking=True)\n\n        logits = model(imgs)\n        loss = loss_fn(logits, targets)\n\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        train_loss += loss.item()\n    train_loss /= len(train_loader)\n\n    # Validation\n    model.eval()\n    val_loss = 0\n\n    all_probs = []\n    all_targets = []\n\n    with torch.inference_mode():\n        for keys, imgs, targets in tqdm(val_loader, desc=\"Validation\"):\n            imgs, targets = imgs.to(device, non_blocking=True), targets.to(device, non_blocking=True)\n\n            logits = model(imgs)\n            loss = loss_fn(logits, targets)\n            probs = torch.sigmoid(logits)\n\n            val_loss += loss.item()\n\n            all_probs.append(probs)\n            all_targets.append(targets)\n\n    val_loss /= len(val_loader)\n    all_probs = torch.cat(all_probs, dim=0)\n    all_targets = torch.cat(all_targets, dim=0)\n\n    all_preds = (all_probs >= 0.5).int()\n\n    val_accuracy = accuracy(all_preds, all_targets.int(), task=\"multilabel\", num_labels=14)\n    val_precision = precision(all_preds, all_targets.int(), task=\"multilabel\", num_labels=14)\n    val_recall = recall(all_preds, all_targets.int(), task=\"multilabel\", num_labels=14)\n    val_auroc = auroc(all_probs, all_targets.int(), task=\"multilabel\", num_labels=14)\n\n\n    if val_auroc > best_score:\n        best_score = val_auroc\n        initial_best_model = model.module.state_dict() if torch.cuda.device_count() > 1 else model.state_dict()\n        torch.save(initial_best_model, \"initial_best_model.pth\")\n        print(f\"New best auroc score: {best_score:.4f}\")\n\n    print(\n        f\"Epoch {epoch+1}/{epochs} | \"\n        f\"Train Loss: {train_loss:.4f} | \"\n        f\"Val Loss: {val_loss:.4f} | \"\n        f\"Acc: {val_accuracy:.4f} | \"\n        f\"Prec: {val_precision:.4f} | \"\n        f\"Rec: {val_recall:.4f} | \"\n        f\"AUROC: {val_auroc:.4f}\"\n    )","metadata":{"execution":{"iopub.status.busy":"2025-09-20T19:46:48.159626Z","iopub.execute_input":"2025-09-20T19:46:48.160403Z","iopub.status.idle":"2025-09-20T22:09:58.630500Z","shell.execute_reply.started":"2025-09-20T19:46:48.160371Z","shell.execute_reply":"2025-09-20T22:09:58.629701Z"},"trusted":true},"outputs":[{"name":"stderr","text":"Training: 100%|██████████| 1343/1343 [39:08<00:00,  1.75s/it]\nValidation: 100%|██████████| 336/336 [08:22<00:00,  1.50s/it]\n","output_type":"stream"},{"name":"stdout","text":"New best auroc score: 0.8678\nEpoch 1/3 | Train Loss: 0.4996 | Val Loss: 0.4623 | Acc: 0.8537 | Prec: 0.7593 | Rec: 0.6225 | AUROC: 0.8678\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 1343/1343 [39:11<00:00,  1.75s/it]\nValidation: 100%|██████████| 336/336 [08:21<00:00,  1.49s/it]\n","output_type":"stream"},{"name":"stdout","text":"New best auroc score: 0.8879\nEpoch 2/3 | Train Loss: 0.4307 | Val Loss: 0.4170 | Acc: 0.8673 | Prec: 0.7782 | Rec: 0.6691 | AUROC: 0.8879\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 1343/1343 [39:44<00:00,  1.78s/it]\nValidation: 100%|██████████| 336/336 [08:20<00:00,  1.49s/it]\n","output_type":"stream"},{"name":"stdout","text":"New best auroc score: 0.8978\nEpoch 3/3 | Train Loss: 0.4037 | Val Loss: 0.3996 | Acc: 0.8731 | Prec: 0.7889 | Rec: 0.6845 | AUROC: 0.8978\n","output_type":"stream"}],"execution_count":15},{"cell_type":"markdown","source":"### Finetuning using AdaAugment and Focal Loss","metadata":{}},{"cell_type":"code","source":"randm, randt = False, False\n\nada_augment=AdaAugment(rand_m=randm, rand_t=randt)\ntrain_set = XRayDataset(train_df, train=True, transform=ada_augment)\n\nw_ = torch.tensor(train_set.df[\"weight\"], dtype=torch.float32)\nsampler = torch.utils.data.WeightedRandomSampler(\n    weights=w_,\n    num_samples=len(w_),\n    replacement=True\n)\n\n# New dataset using adaptive augmentations\ntrain_loader = DataLoader(\n    train_set, \n    batch_size=batch_size,\n    #sampler=sampler,\n    shuffle=True, \n    pin_memory=True,\n    num_workers=os.cpu_count()\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-21T00:02:37.153458Z","iopub.execute_input":"2025-09-21T00:02:37.154248Z","iopub.status.idle":"2025-09-21T00:02:37.206886Z","shell.execute_reply.started":"2025-09-21T00:02:37.154209Z","shell.execute_reply":"2025-09-21T00:02:37.206161Z"}},"outputs":[],"execution_count":134},{"cell_type":"code","source":"get_model, in_features = models_[model_name]\n\nmodel = get_model(fine_tune=True)\n\nmodel.load_state_dict(torch.load(\"/kaggle/working/initial_best_model.pth\", map_location=device, weights_only=False))\n\noptimizer = torch.optim.Adam(params=model.parameters(), lr=1e-5)\n\nloss_fn = FocalLoss(weights=torch.tensor(class_weights, dtype=torch.float32), reduction=\"none\")\n\nagent = Agent(in_features, len(augmentation_space), not randt, not randm)\ncurrent_state = {}\nbest_score = 0","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-21T00:02:38.449165Z","iopub.execute_input":"2025-09-21T00:02:38.449660Z","iopub.status.idle":"2025-09-21T00:02:39.131126Z","shell.execute_reply.started":"2025-09-21T00:02:38.449633Z","shell.execute_reply":"2025-09-21T00:02:39.130325Z"}},"outputs":[],"execution_count":135},{"cell_type":"code","source":"def _register_head_hook(model):\n    def hook(module, input, output):\n        current_state['head_input'] = input[0].detach()\n    \n    if isinstance(model, torch.nn.DataParallel):\n        return model.module.classifier[-1].register_forward_hook(hook)\n    elif isinstance(model, models.ConvNeXt):\n        return model.classifier[2].register_forward_hook(hook)\n    else:\n        return model.classifier[-1].register_forward_hook(hook)\n\ndef _remove_head_hook(_hook_handle):\n    _hook_handle.remove()\n\n\nepochs = 5\nr_weight = 0.5\nmodel.to(device)\n\nif torch.cuda.device_count() > 1:\n    agent = nn.DataParallel(agent)\n\nagent.to(device)\n\n\nif torch.cuda.device_count() > 1:\n    print(f\"Using {torch.cuda.device_count()} GPUs\")\n    model = nn.DataParallel(model)\n    \nfor epoch in range(epochs):\n    # Training\n    \n    model.train()\n    handle = _register_head_hook(model)\n    \n    train_loss, total_actor_loss, total_critic_loss = 0, 0, 0\n    for keys, imgs, targets in tqdm(train_loader, desc=\"Training\"):\n        imgs, targets = imgs.to(device, non_blocking=True), targets.to(device, non_blocking=True)\n\n        logits = model(imgs)\n        state = current_state[\"head_input\"]\n\n        loss = loss_fn(logits, targets)\n        if isinstance(agent, nn.DataParallel):\n            prev_loss = agent.module.loss_memory(keys, loss.detach())\n        else:\n            prev_loss = agent.loss_memory(keys, loss.detach())\n        probs = torch.sigmoid(logits)\n\n        action, transform_idx = agent(state)\n        ada_augment.set(keys, action, transform_idx)\n\n        entropy = torch.sum(probs * torch.log(probs + 1e-8), dim=1).unsqueeze(1)\n        reward = r_weight * (loss.detach().mean() - prev_loss.mean()) + (1 - r_weight) * entropy\n\n        if isinstance(agent, nn.DataParallel):\n            actor_loss, critic_loss = agent.module.update(keys, state, reward)\n        else:\n            actor_loss, critic_loss = agent.update(keys, state, reward)\n\n        loss = loss.mean()\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        train_loss += loss.item()\n        total_actor_loss += actor_loss.item()\n        total_critic_loss += critic_loss.item()\n    train_loss /= len(train_loader)\n    total_actor_loss /= len(train_loader)\n    total_critic_loss /= len(train_loader)\n\n    _remove_head_hook(handle)\n    # Validation\n    model.eval()\n    val_loss = 0\n\n    all_probs = []\n    all_targets = []\n\n    with torch.inference_mode():\n        for keys, imgs, targets in tqdm(val_loader, desc=\"Validation\"):\n            imgs, targets = imgs.to(device, non_blocking=True), targets.to(device, non_blocking=True)\n\n            logits = model(imgs)\n            loss = loss_fn(logits, targets)\n            loss = loss.mean()\n            probs = torch.sigmoid(logits)\n\n            val_loss += loss.item()\n\n            all_probs.append(probs)\n            all_targets.append(targets)\n\n    val_loss /= len(val_loader)\n    all_probs = torch.cat(all_probs, dim=0)\n    all_targets = torch.cat(all_targets, dim=0)\n\n    all_preds = (all_probs >= 0.5).int()\n\n    val_accuracy = accuracy(all_preds, all_targets.int(), task=\"multilabel\", num_labels=14)\n    val_precision = precision(all_preds, all_targets.int(), task=\"multilabel\", num_labels=14)\n    val_recall = recall(all_preds, all_targets.int(), task=\"multilabel\", num_labels=14)\n    val_auroc = auroc(all_probs, all_targets.int(), task=\"multilabel\", num_labels=14)\n\n    if val_auroc > best_score:\n        best_score = val_auroc\n        initial_best_model = model.module.state_dict() if torch.cuda.device_count() > 1 else model.state_dict()\n        torch.save(initial_best_model, \"best_model.pth\")\n        print(f\"New best auroc score: {best_score:.4f}\")\n\n    print(\n        f\"Epoch {epoch+1}/{epochs} | \"\n        f\"Train Loss: {train_loss:.4f} | \"\n        f\"Actor Loss: {total_actor_loss:.4f} |\"\n        f\"Critic Loss: {total_critic_loss:.4f} |\"\n        f\"Val Loss: {val_loss:.4f} | \"\n        f\"Acc: {val_accuracy:.4f} | \"\n        f\"Prec: {val_precision:.4f} | \"\n        f\"Rec: {val_recall:.4f} | \"\n        f\"AUROC: {val_auroc:.4f}\"\n    )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-21T00:02:42.874800Z","iopub.execute_input":"2025-09-21T00:02:42.875149Z","iopub.status.idle":"2025-09-21T00:44:03.339821Z","shell.execute_reply.started":"2025-09-21T00:02:42.875123Z","shell.execute_reply":"2025-09-21T00:44:03.338450Z"}},"outputs":[{"name":"stderr","text":"Training: 100%|██████████| 1343/1343 [33:01<00:00,  1.48s/it]\nValidation: 100%|██████████| 336/336 [08:18<00:00,  1.48s/it]\n","output_type":"stream"},{"name":"stdout","text":"New best auroc score: 0.9000\nEpoch 1/5 | Train Loss: 0.3694 | Actor Loss: -0.0000 |Critic LOss: 0.0000 |Val Loss: 0.3917 | Acc: 0.8758 | Prec: 0.7905 | Rec: 0.6962 | AUROC: 0.9000\n","output_type":"stream"},{"name":"stderr","text":"Training:   0%|          | 0/1343 [00:00<?, ?it/s]\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_36/3601778896.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_actor_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_critic_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Training\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0mimgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1181\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1182\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1183\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 708\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    709\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m             if (\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1478\u001b[0m                 \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1479\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rcvd_idx\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1480\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1481\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1482\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1504\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1505\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1506\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1507\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    731\u001b[0m             \u001b[0;31m# instantiate since we don't know how to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    732\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 733\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    734\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Caught ValueError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/worker.py\", line 349, in _worker_loop\n    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/fetch.py\", line 52, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/fetch.py\", line 52, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n            ~~~~~~~~~~~~^^^^^\n  File \"/tmp/ipykernel_36/2681218998.py\", line 30, in __getitem__\n    img = self.transform(key, img)\n          ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/tmp/ipykernel_36/210989075.py\", line 39, in __call__\n    m = float(m)\n        ^^^^^^^^\nValueError: only one element tensors can be converted to Python scalars\n"],"ename":"ValueError","evalue":"Caught ValueError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/worker.py\", line 349, in _worker_loop\n    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/fetch.py\", line 52, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/fetch.py\", line 52, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n            ~~~~~~~~~~~~^^^^^\n  File \"/tmp/ipykernel_36/2681218998.py\", line 30, in __getitem__\n    img = self.transform(key, img)\n          ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/tmp/ipykernel_36/210989075.py\", line 39, in __call__\n    m = float(m)\n        ^^^^^^^^\nValueError: only one element tensors can be converted to Python scalars\n","output_type":"error"}],"execution_count":137},{"cell_type":"code","source":"def create_submission(model_name=model_name):\n    get_model, _ = models_[model_name]\n    model = get_model()\n    model.load_state_dict(torch.load(\"/kaggle/working/best_model.pth\", map_location=device, weights_only=False))\n\n    model.to(device)\n    model.eval()\n    \n    all_keys = []\n    all_probs = []\n    \n    with torch.inference_mode():\n        for key, img in tqdm(test_loader):\n            img = img.to(device)\n\n            out = model(img)\n            probs = torch.sigmoid(out)\n\n            all_keys.extend(key)\n            all_probs.append(probs.cpu().numpy())\n            \n    all_probs = np.stack(all_probs, axis=1)\n\n    return all_keys, all_probs","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-20T19:46:32.672691Z","iopub.status.idle":"2025-09-20T19:46:32.672889Z","shell.execute_reply.started":"2025-09-20T19:46:32.672793Z","shell.execute_reply":"2025-09-20T19:46:32.672802Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"all_keys, all_probs = create_submission()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-20T19:46:32.673604Z","iopub.status.idle":"2025-09-20T19:46:32.673818Z","shell.execute_reply.started":"2025-09-20T19:46:32.673722Z","shell.execute_reply":"2025-09-20T19:46:32.673731Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"threshold = 0.5\nfinal_submission = pd.DataFrame()\nfinal_submission[\"Image_name\"] = all_keys\nfinal_submission[label_columns] = (all_probs > threshold).astype(int)\nfinal_submission.to_csv('/kaggle/working/submission.csv', index=False)\n\nprint(\"=\"* 60)\nprint(\"Final submission file created at /kaggle/working/submission.csv\")\nprint(\"=\"* 60)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-20T19:46:32.674399Z","iopub.status.idle":"2025-09-20T19:46:32.674693Z","shell.execute_reply.started":"2025-09-20T19:46:32.674517Z","shell.execute_reply":"2025-09-20T19:46:32.674533Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pd.read_csv(\"/kaggle/working/submission.csv\").describe()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-20T19:46:32.675700Z","iopub.status.idle":"2025-09-20T19:46:32.675980Z","shell.execute_reply.started":"2025-09-20T19:46:32.675856Z","shell.execute_reply":"2025-09-20T19:46:32.675871Z"}},"outputs":[],"execution_count":null}]}