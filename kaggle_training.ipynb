{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":112899,"databundleVersionId":13449579,"sourceType":"competition"}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torchvision import models, transforms\nfrom torchmetrics.functional import accuracy, recall, precision, auroc\nfrom torch.utils.data import Dataset, DataLoader\nimport timm\nimport numpy as np\nimport pandas as pd\nimport random\nfrom typing import List\nfrom tqdm import tqdm\nfrom torchmetrics.functional import accuracy, recall, precision, auroc\nfrom PIL import Image, ImageEnhance, ImageOps, ImageFilter\nimport os\nfrom glob import glob\nfrom sklearn.model_selection import train_test_split\n\nBASE_DIR = \"/kaggle/input/grand-xray-slam-division-a\"\nlabel_columns = [\n    'Atelectasis', 'Cardiomegaly', 'Consolidation', 'Edema', 'Enlarged Cardiomediastinum',\n    'Fracture', 'Lung Lesion', 'Lung Opacity', 'No Finding', 'Pleural Effusion',\n    'Pleural Other', 'Pneumonia', 'Pneumothorax', 'Support Devices'\n]\n\n\ndef setup_seed(seed=None):\n    if seed is None:\n        return\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    np.random.seed(seed)\n    random.seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"execution":{"iopub.status.busy":"2025-09-20T12:14:44.984846Z","iopub.execute_input":"2025-09-20T12:14:44.985153Z","iopub.status.idle":"2025-09-20T12:15:01.423432Z","shell.execute_reply.started":"2025-09-20T12:14:44.985129Z","shell.execute_reply":"2025-09-20T12:15:01.422555Z"},"trusted":true},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"### Augmentation Spaces and Utilities","metadata":{}},{"cell_type":"code","source":"# used to freeze layers in a model\ndef freeze_all(model):\n    for param in model.parameters():\n        param.requires_grad=False\n\ndef get_resnet18(num_classes=14, fine_tune=True):\n    model = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n\n    if fine_tune:\n        freeze_all(model)\n        for param in model.layer4.parameters():\n            param.requires_grad = True\n\n    model.fc = nn.Linear(512, num_classes)\n    return model\n\ndef get_resnet34(num_classes=14, fine_tune=True):\n    model = models.resnet34(weights=models.ResNet34_Weights.IMAGENET1K_V1)\n\n    if fine_tune:\n        freeze_all(model)\n        for param in model.layer4.parameters():\n            param.requires_grad = True\n\n    model.fc = nn.Linear(512, num_classes)\n    return model\n\ndef get_effnetb0(num_classes=14, fine_tune=True):\n    model = models.efficientnet_b0(weights=models.EfficientNet_B0_Weights.IMAGENET1K_V1)\n\n    if fine_tune:\n        freeze_all(model)\n        for idx in range(6, 8):\n            for param in model.features[idx].parameters():\n                param.requires_grad = True\n\n    model.classifier = nn.Sequential(\n        nn.Dropout(p=0.2, inplace=True),\n        nn.Linear(in_features=1280, out_features=num_classes)\n    )\n    \n    return model\n\ndef get_convnext_tiny(num_classes=14, fine_tune=True):\n    model = models.convnext_tiny(weights=models.ConvNeXt_Tiny_Weights.IMAGENET1K_V1)\n\n    if fine_tune:\n        freeze_all(model)\n        for param in model.features[6].parameters():\n            param.requires_grad = True\n\n    model.classifier[2] = nn.Linear(in_features=768, out_features=num_classes)\n    return model\n\n# returns getter function and number of in features of the classifier\nmodels_ = {\n    \"res18\": (get_resnet18, 512),\n    \"res34\": (get_resnet34, 512),\n    \"effb0\": (get_effnetb0, 1280),\n    \"convnext\" : (get_convnext_tiny, 768),\n}","metadata":{"execution":{"iopub.status.busy":"2025-09-19T20:07:01.691183Z","iopub.execute_input":"2025-09-19T20:07:01.691503Z","iopub.status.idle":"2025-09-19T20:07:01.702331Z","shell.execute_reply.started":"2025-09-19T20:07:01.691482Z","shell.execute_reply":"2025-09-19T20:07:01.701070Z"},"trusted":true},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# Set up transforms\nbasic_transforms = transforms.Compose([\n    transforms.Resize((224, 224)), # resize to 224x224\n    transforms.ToTensor(), # convert to tensor [0,1]\n    transforms.Normalize( # normalize with ImageNet stats\n        mean=[0.485, 0.456, 0.406],\n        std=[0.229, 0.224, 0.225]\n    )\n])\n\n# custom transforms with adaptive magnitude\ndef shear_x(img, magnitude):\n    level = magnitude * 0.3 * random.choice([-1, 1])\n    return img.transform(img.size, Image.AFFINE, (1, level, 0, 0, 1, 0))\n\ndef shear_y(img, magnitude):\n    level = magnitude * 0.3 * random.choice([-1, 1])\n    return img.transform(img.size, Image.AFFINE, (1, 0, 0, level, 1, 0))\n\ndef translate_x(img, magnitude):\n    max_shift = 0.3 * img.size[0]\n    level = magnitude * max_shift * random.choice([-1, 1])\n    return img.transform(img.size, Image.AFFINE, (1, 0, level, 0, 1, 0))\n\ndef translate_y(img, magnitude):\n    max_shift = 0.3 * img.size[1]\n    level = magnitude * max_shift * random.choice([-1, 1])\n    return img.transform(img.size, Image.AFFINE, (1, 0, 0, 0, 1, level))\n\ndef rotate(img, magnitude):\n    degrees = magnitude * 30 * random.choice([-1, 1])\n    return img.rotate(degrees)\n\ndef contrast(img, magnitude):\n    enhancer = ImageEnhance.Contrast(img)\n    factor = 1.0 + (magnitude * random.choice([-0.9, 0.9]))\n    return enhancer.enhance(factor)\n\ndef brightness(img, magnitude):\n    enhancer = ImageEnhance.Brightness(img)\n    factor = 1.0 + (magnitude * random.choice([-0.9, 0.9]))\n    return enhancer.enhance(factor)\n\ndef sharpness(img, magnitude):\n    enhancer = ImageEnhance.Sharpness(img)\n    factor = 1.0 + (magnitude * random.choice([-0.9, 0.9]))\n    return enhancer.enhance(factor)\n\ndef equalize(img, magnitude=None):\n    return ImageOps.equalize(img)\n\ndef gaussian_blur(img, magnitude):\n    radius = magnitude * 2\n    return img.filter(ImageFilter.GaussianBlur(radius))\n\ndef identity(img, magnitude=None):\n    return img\n\naugmentation_space = [\n    shear_x, shear_y, \n    translate_x, translate_y,\n    rotate, equalize, \n    contrast, brightness, \n    sharpness, identity\n]","metadata":{"execution":{"iopub.status.busy":"2025-09-19T20:07:04.364600Z","iopub.execute_input":"2025-09-19T20:07:04.364994Z","iopub.status.idle":"2025-09-19T20:07:04.383253Z","shell.execute_reply.started":"2025-09-19T20:07:04.364961Z","shell.execute_reply":"2025-09-19T20:07:04.381845Z"},"trusted":true},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# AdaAugment can be used to control augmentation magnitudes and operations\n\nclass AdaAugment:\n\n    def __init__(self, rand_m, rand_t):\n        self.key_transform = {}\n        self.key_magnitude = {}\n        self.transforms = augmentation_space\n        self.rand_m = rand_m\n        self.rand_t = rand_t\n\n    def set(self, keys, m, transform_idx=None):\n        for i, key in enumerate(keys):\n            self.key_magnitude[key] = m[i].cpu().detach()\n        \n        if transform_idx is not None:\n            for i, key in enumerate(keys):\n                self.key_transform[key] = transform_idx[i].cpu().detach()\n\n    def __call__(self, key, img):\n        # Get Magnitude for the sample\n        m = self.key_magnitude.get(key)\n        if m is None:  \n            if self.rand_m:\n                if random.random() < 0.4:\n                    return img  # skip transform\n                m = random.random() # select a random magnitude\n            else:\n                m = 0\n        else:\n            m = float(m)\n    \n        # Get transform\n        t = self.key_transform.get(key)\n        if t is None:\n            t = random.choice(self.transforms) if self.rand_t else self.transforms[-1] # if rand_t => select random augementation => else => use identiy as first transformation\n        else:\n            t = self.transforms[int(t)]\n\n        return t(img, m) # return applied transformation with corresponding magnitude\n","metadata":{"execution":{"iopub.status.busy":"2025-09-19T20:07:06.625657Z","iopub.execute_input":"2025-09-19T20:07:06.625973Z","iopub.status.idle":"2025-09-19T20:07:06.634260Z","shell.execute_reply.started":"2025-09-19T20:07:06.625945Z","shell.execute_reply":"2025-09-19T20:07:06.633270Z"},"trusted":true},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# Focal Loss for fine tuninng\n\nclass FocalLoss(nn.Module):\n\n    def __init__(self, weights:List=None, gamma=2.0, reduction=\"mean\"):\n        super().__init__()\n\n        self.weights = weights\n        self.gamma = gamma\n        self.reduction = reduction\n\n    def forward(self, logit, target):\n        bce_loss = nn.functional.binary_cross_entropy_with_logits(\n            logit, target,\n            reduction=\"none\"\n        )\n        probs = torch.exp(-bce_loss)\n        F_loss = self.weights.to(target.device) * (1-probs) ** self.gamma * bce_loss\n\n        if self.reduction == \"mean\":\n            return F_loss.mean()\n        elif self.reduction == \"none\":\n            return F_loss   \n        else:\n            return F_loss.sum()","metadata":{"execution":{"iopub.status.busy":"2025-09-19T20:07:09.853884Z","iopub.execute_input":"2025-09-19T20:07:09.854294Z","iopub.status.idle":"2025-09-19T20:07:09.861788Z","shell.execute_reply.started":"2025-09-19T20:07:09.854265Z","shell.execute_reply":"2025-09-19T20:07:09.860633Z"},"trusted":true},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# Saves per sample information such as previous loss etc.\n\nclass ValueMemory:\n    def __init__(self):\n        \"\"\"\n        Stores the last value per key (no EMA).\n        \"\"\"\n        self.values = {}\n\n    def __call__(self, keys, vals):\n        \"\"\"\n        keys: list of sample identifiers\n        vals: torch.Tensor of shape (len(keys), D)\n        Returns: current stored values, previous stored values\n        \"\"\"\n        stored_list = []\n        new_list = []\n\n        for i, key in enumerate(keys):\n            val = vals[i]\n            if key not in self.values:\n                old = val.clone()  # nothing stored yet → use current\n            else:\n                old = self.values[key]\n\n            self.values[key] = val  # overwrite with last value\n\n            stored_list.append(old.unsqueeze(0))\n            new_list.append(self.values[key].unsqueeze(0))\n\n        stored = torch.cat(stored_list, dim=0)  # previous values\n        return stored\n\n    def get(self, key):\n        \"\"\"\n        Access the stored value for a single key\n        \"\"\"\n        return self.values.get(key, None)\n\n    def get_multi(self, keys):\n        \"\"\"\n        Access stored values for multiple keys\n        \"\"\"\n        return torch.stack([self.values[k] for k in keys])","metadata":{"execution":{"iopub.status.busy":"2025-09-19T20:07:11.753968Z","iopub.execute_input":"2025-09-19T20:07:11.754682Z","iopub.status.idle":"2025-09-19T20:07:11.762435Z","shell.execute_reply.started":"2025-09-19T20:07:11.754654Z","shell.execute_reply":"2025-09-19T20:07:11.761321Z"},"trusted":true},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"### Setting up the AdaAugment Agent\n+ Critic => returns value for a state\n+ Actor => Parameterizes a beta distribution that is used to sample augmentation magnitudes\n+ Controller => Parameterizes a categorical distribution that is used to sample transformations from the augmentation space","metadata":{}},{"cell_type":"code","source":"class Actor(nn.Module):\n    def __init__(self, in_features, hidden, out_features):\n        super().__init__()\n        self.linear1 = nn.Linear(in_features, hidden)\n        self.layer_norm1 = nn.LayerNorm(hidden)\n        self.linear2 = nn.Linear(hidden, hidden)\n        self.alpha_head = nn.Linear(hidden, out_features)\n        self.beta_head = nn.Linear(hidden, out_features)\n\n    def forward(self, x):\n        x = torch.relu(self.linear1(self.layer_norm1(x)))\n        x = torch.relu(self.linear2(x))\n        return torch.softmax(self.alpha_head(x), dim=-1) + 1, torch.softmax(self.beta_head(x), dim=-1) + 1\n\n    def get_dist(self, x):\n        alpha, beta = self(x)\n        dist = torch.distributions.Beta(alpha, beta)\n        return dist\n\n\nclass Critic(nn.Module):\n\n    def __init__(self, in_features, hidden):\n        super().__init__()\n        self.linear1 = nn.Linear(in_features, hidden)\n        self.layer_norm1 = nn.LayerNorm(hidden)\n        self.linear2 = nn.Linear(hidden, hidden)\n        self.head = nn.Linear(hidden, 1)\n\n    def forward(self, x):\n        x = torch.relu(self.linear1(self.layer_norm1(x)))\n        x = torch.relu(self.linear2(x))\n        return self.head(x)\n\n\nclass Controller(nn.Module):\n\n    def __init__(self, in_features, hidden):\n        super().__init__()\n        self.linear1 = nn.Linear(in_features, hidden)\n        self.layer_norm1 = nn.LayerNorm(hidden)\n        self.linear2 = nn.Linear(hidden, hidden)\n        self.head = nn.Linear(hidden, len(augmentation_space))\n\n    def forward(self, x):\n        x = torch.relu(self.linear1(self.layer_norm1(x)))\n        x = torch.relu(self.linear2(x))\n        return self.head(x)\n    \n    def get_dist(self, x):\n        out = self(x)\n        dist = torch.distributions.Categorical(logits=out)\n        return dist\n\n\nclass Agent(nn.Module):\n\n    def __init__(self, in_features, control=False, actor=False):\n        super().__init__()\n        self.val_memory = ValueMemory()\n        self.loss_memory = ValueMemory()\n\n        self.critic = Critic(in_features=in_features, hidden=128)\n\n        self.store_ = {}\n\n        self.control_ = control\n        self.actor_ = actor\n        if control:\n            self.controller = Controller(in_features=in_features, hidden=128)\n\n        if actor:\n            self.actor = Actor(in_features=in_features, hidden=128, out_features=1) \n\n        self.actor_optimizer = torch.optim.Adam(\n            params=self.actor.parameters(), lr=3e-5, weight_decay=5e-4\n        )\n        self.critic_optimizer = torch.optim.Adam(\n            params=self.critic.parameters(), lr=3e-5, weight_decay=5e-4\n        )\n\n    def action(self, state):\n        action_actor = None\n        action_controller = None\n        if self.actor_:  \n            dist = self.actor.get_dist(state.detach())\n            action_actor = dist.sample()\n            self.store_[\"action_actor\"] = action_actor\n            self.store_[\"dist_actor\"] = dist\n        if self.control_:\n            dist = self.controller.get_dist(state.detach())\n            action_controller = dist.sample()\n            self.store_[\"action_controller\"] = action_controller\n            self.store_[\"dist_controller\"] = dist\n\n        return action_actor, action_controller\n\n    def update(self, key, state, reward):\n        value = self.critic(state)\n        prev_state = self.val_memory(key, state)\n        prev_value = self.critic(prev_state)\n        \n        with torch.no_grad():\n            td_target = reward + 0.99 * value\n\n        if self.actor_ and self.control_:\n            dist_actor, action_actor = self.store_[\"dist_actor\"], self.store_[\"action_actor\"]\n            dist_control, action_control = self.store_[\"dist_controller\"], self.store_[\"action_controller\"]\n\n            log_prob_actor = dist_actor.log_prob(action_actor)\n            log_prob_control = dist_control.log_prob(action_control)\n\n            log_prob = log_prob_actor + log_prob_control  \n\n        elif self.actor_:\n            dist, action = self.store_[\"dist_actor\"], self.store_[\"action_actor\"]\n            log_prob = dist.log_prob(action)\n\n        elif self.control_:\n            dist, action = self.store_[\"dist_controller\"], self.store_[\"action_controller\"]\n            log_prob = dist.log_prob(action)\n\n        actor_loss = -(log_prob * (td_target - prev_value.detach())).mean()\n\n        self.actor_optimizer.zero_grad()\n        actor_loss.backward()\n        self.actor_optimizer.step()\n\n        critic_loss = torch.nn.functional.mse_loss(td_target, prev_value)\n        self.critic_optimizer.zero_grad()\n        critic_loss.backward()\n        self.critic_optimizer.step()\n\n        return actor_loss, critic_loss","metadata":{"execution":{"iopub.status.busy":"2025-09-19T20:07:14.465071Z","iopub.execute_input":"2025-09-19T20:07:14.465535Z","iopub.status.idle":"2025-09-19T20:07:14.497417Z","shell.execute_reply.started":"2025-09-19T20:07:14.465502Z","shell.execute_reply":"2025-09-19T20:07:14.496057Z"},"trusted":true},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":"### Dataset\n+ Class weights\n+ Dataset class","metadata":{}},{"cell_type":"code","source":"def get_class_weights(df):\n    weights = []\n    label_columns = [\n        'Atelectasis', 'Cardiomegaly', 'Consolidation', 'Edema', 'Enlarged Cardiomediastinum',\n        'Fracture', 'Lung Lesion', 'Lung Opacity', 'No Finding', 'Pleural Effusion',\n        'Pleural Other', 'Pneumonia', 'Pneumothorax', 'Support Devices'\n    ]\n\n    for label in label_columns:\n        weight = len(df) / (df[label].sum() + 1e-6)\n        weights.append(weight)\n\n    return weights","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-19T20:07:25.468504Z","iopub.execute_input":"2025-09-19T20:07:25.469224Z","iopub.status.idle":"2025-09-19T20:07:25.475563Z","shell.execute_reply.started":"2025-09-19T20:07:25.469192Z","shell.execute_reply":"2025-09-19T20:07:25.473928Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"class XRayDataset(Dataset):\n\n    def __init__(self, df, train=True, transform=None):\n        super().__init__()\n        self.df = df\n        self.train = train\n        self.transform = transform\n        self.label_columns = [\n            'Atelectasis', 'Cardiomegaly', 'Consolidation', 'Edema', 'Enlarged Cardiomediastinum',\n            'Fracture', 'Lung Lesion', 'Lung Opacity', 'No Finding', 'Pleural Effusion',\n            'Pleural Other', 'Pneumonia', 'Pneumothorax', 'Support Devices'\n        ]\n        if train:\n            class_weights = np.array(get_class_weights(df), dtype=np.float32)\n    \n            sample_weights = (df[label_columns].values.astype(np.float32) * class_weights).mean(axis=1)\n            sample_weights[sample_weights == 0] = 1.0\n            self.df[\"weight\"] = sample_weights\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        img_path = self.df.iloc[idx][\"img_path\"]\n        img = Image.open(img_path).convert(\"RGB\")\n        label = self.df.iloc[idx][self.label_columns].values.astype(np.float32)\n        key = self.df.iloc[idx][\"Image_name\"]\n        \n        if self.train and self.transform is not None:\n            img = self.transform(key, img)\n\n        img = basic_transforms(img)\n\n        if not self.train:\n            return key, img\n\n        return key, img, torch.tensor(label, dtype=torch.float32)","metadata":{"execution":{"iopub.status.busy":"2025-09-19T20:07:26.933731Z","iopub.execute_input":"2025-09-19T20:07:26.934082Z","iopub.status.idle":"2025-09-19T20:07:26.942731Z","shell.execute_reply.started":"2025-09-19T20:07:26.934049Z","shell.execute_reply":"2025-09-19T20:07:26.941733Z"},"trusted":true},"outputs":[],"execution_count":12},{"cell_type":"markdown","source":"### Adapt entire Model to new dataset","metadata":{}},{"cell_type":"code","source":"train_csv = pd.read_csv(\"/kaggle/input/grand-xray-slam-division-a/train1.csv\")\ntrain_csv[\"img_path\"] = train_csv[\"Image_name\"].apply(lambda x: os.path.join(BASE_DIR, \"train1\", x))\nsubmission_df = pd.read_csv(\"/kaggle/input/grand-xray-slam-division-a/sample_submission_1.csv\")\ntrain_df, val_df = train_test_split(\n    train_csv,\n    test_size=0.2,\n    random_state=42,\n    stratify=train_csv[\"No Finding\"]\n)\n\nsubmission_df[\"img_path\"] = submission_df[\"Image_name\"].apply(lambda x : os.path.join(BASE_DIR, \"test1\", x))\nclass_weights = get_class_weights(train_df)\nzipped_class_weights = list(zip(label_columns, class_weights))\n\nfor class_, weight in zipped_class_weights:\n    print(f\"{class_}: {weight:.3f}\\n\")","metadata":{"execution":{"iopub.status.busy":"2025-09-19T20:07:29.669060Z","iopub.execute_input":"2025-09-19T20:07:29.669674Z","iopub.status.idle":"2025-09-19T20:07:30.497312Z","shell.execute_reply.started":"2025-09-19T20:07:29.669647Z","shell.execute_reply":"2025-09-19T20:07:30.496304Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Atelectasis: 2.765\n\nCardiomegaly: 3.073\n\nConsolidation: 3.666\n\nEdema: 4.034\n\nEnlarged Cardiomediastinum: 2.841\n\nFracture: 7.221\n\nLung Lesion: 9.104\n\nLung Opacity: 2.211\n\nNo Finding: 3.162\n\nPleural Effusion: 3.137\n\nPleural Other: 15.225\n\nPneumonia: 7.571\n\nPneumothorax: 12.202\n\nSupport Devices: 2.852\n\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"# Dataset\ntrain_set = XRayDataset(train_df, train=True)\nval_set = XRayDataset(val_df, train=True)\ntest_set = XRayDataset(submission_df, train=False)\n\n# DataLoader\nbatch_size = 32\ntrain_loader = DataLoader(\n    train_set, \n    batch_size=batch_size, \n    shuffle=True, \n    pin_memory=True,\n    num_workers=os.cpu_count()\n)\nval_loader = DataLoader(\n    val_set, \n    batch_size=batch_size, \n    pin_memory=True,\n    num_workers=os.cpu_count()\n)\ntest_loader = DataLoader(\n    test_set, \n    batch_size=batch_size, \n    pin_memory=True,\n    num_workers=os.cpu_count()\n)","metadata":{"execution":{"iopub.status.busy":"2025-09-19T20:07:35.701745Z","iopub.execute_input":"2025-09-19T20:07:35.702065Z","iopub.status.idle":"2025-09-19T20:07:35.747118Z","shell.execute_reply.started":"2025-09-19T20:07:35.702041Z","shell.execute_reply":"2025-09-19T20:07:35.746115Z"},"trusted":true},"outputs":[],"execution_count":14},{"cell_type":"code","source":"# Models and functions\nmodel_name = \"res18\"\nget_model, in_features = models_[model_name]\nmodel = get_effnetb0(fine_tune=False)\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\nbce_loss = torch.nn.BCEWithLogitsLoss(pos_weight=torch.tensor(class_weights).to(device))","metadata":{"execution":{"iopub.status.busy":"2025-09-19T20:07:54.846748Z","iopub.execute_input":"2025-09-19T20:07:54.847434Z","iopub.status.idle":"2025-09-19T20:07:55.319067Z","shell.execute_reply.started":"2025-09-19T20:07:54.847393Z","shell.execute_reply":"2025-09-19T20:07:55.317921Z"},"trusted":true},"outputs":[{"name":"stderr","text":"Downloading: \"https://download.pytorch.org/models/efficientnet_b0_rwightman-7f5810bc.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_b0_rwightman-7f5810bc.pth\n100%|██████████| 20.5M/20.5M [00:00<00:00, 131MB/s]\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"epochs = 3\nmodel.to(device)\nbest_score = 0\n\nif torch.cuda.device_count() > 1:\n    print(f\"Using {torch.cuda.device_count()} GPUs\")\n    model = nn.DataParallel(model)\n    \nfor epoch in range(epochs):\n    \n    # Training\n    \n    model.train()\n    train_loss = 0\n    for keys, imgs, targets in tqdm(train_loader, desc=\"Training\"):\n        imgs, targets = imgs.to(device, non_blocking=True), targets.to(device, non_blocking=True)\n\n        logits = model(imgs)\n        loss = bce_loss(logits, targets)\n\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        train_loss += loss.item()\n    train_loss /= len(train_loader)\n\n    # Validation\n    model.eval()\n    val_loss = 0\n\n    all_probs = []\n    all_targets = []\n\n    with torch.inference_mode():\n        for keys, imgs, targets in tqdm(val_loader, desc=\"Validation\"):\n            imgs, targets = imgs.to(device, non_blocking=True), targets.to(device, non_blocking=True)\n\n            logits = model(imgs)\n            loss = bce_loss(logits, targets)\n            probs = torch.sigmoid(logits)\n\n            val_loss += loss.item()\n\n            all_probs.append(probs)\n            all_targets.append(targets)\n\n    val_loss /= len(val_loader)\n    all_probs = torch.cat(all_probs, dim=0)\n    all_targets = torch.cat(all_targets, dim=0)\n\n    val_accuracy  = accuracy(all_probs, all_targets.int(), task=\"multilabel\", num_labels=14)\n    val_precision = precision(all_probs, all_targets.int(), task=\"multilabel\", num_labels=14)\n    val_recall    = recall(all_probs, all_targets.int(), task=\"multilabel\", num_labels=14)\n    val_auroc     = auroc(all_probs, all_targets.int(), task=\"multilabel\", num_labels=14)\n\n    if val_auroc > best_score:\n        best_score = val_auroc\n        initial_best_model = model.module.state_dict() if torch.cuda.device_count() > 1 else model.state_dict()\n        torch.save(initial_best_model, \"intial_best_model.pth\")\n        print(f\"New best auroc score: {best_score:.4f}\")\n\n    print(\n        f\"Epoch {epoch+1}/{epochs} | \"\n        f\"Train Loss: {train_loss:.4f} | \"\n        f\"Val Loss: {val_loss:.4f} | \"\n        f\"Acc: {val_accuracy:.4f} | \"\n        f\"Prec: {val_precision:.4f} | \"\n        f\"Rec: {val_recall:.4f} | \"\n        f\"AUROC: {val_auroc:.4f}\"\n    )","metadata":{"execution":{"iopub.status.busy":"2025-09-19T20:07:57.514476Z","iopub.execute_input":"2025-09-19T20:07:57.514789Z","iopub.status.idle":"2025-09-19T20:08:15.645583Z","shell.execute_reply.started":"2025-09-19T20:07:57.514768Z","shell.execute_reply":"2025-09-19T20:08:15.643644Z"},"trusted":true},"outputs":[{"name":"stderr","text":"Training:   0%|          | 0/2685 [00:18<?, ?it/s]\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_36/3236756535.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    624\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m             )\n\u001b[0;32m--> 626\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    627\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    821\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 823\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    824\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":16},{"cell_type":"markdown","source":"### Finetuning using AdaAugment and Focal Loss","metadata":{}},{"cell_type":"code","source":"randm, randt = True, False\n\nada_augment=AdaAugment(rand_m=randm, rand_t=randt)\ntrain_set = XRayDataset(train_df, train=True, transform=ada_augment)\n\nw_ = torch.tensor(train_set.df[\"weight\"], dtype=torch.float32)\nsampler = torch.utils.data.WeightedRandomSampler(\n    weights=w_,\n    num_samples=len(w_),\n    replacement=True\n)\n\n# New dataset using adaptive augmentations\ntrain_loader = DataLoader(\n    train_set, \n    batch_size=batch_size,\n    #sampler=sampler,\n    shuffle=True, \n    pin_memory=True,\n    num_workers=os.cpu_count()\n)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"get_model, in_features = models_[model_name]\n\nmodel = get_model(fine_tune=True)\n\nmodel.load_state_dict(torch.load(\"initial_best_model.pth\", map_location=device, weights_only=False))\n\noptimizer = torch.optim.Adam(params=model.parameters(), lr=1e-5)\n\nloss_fn = FocalLoss(weights=class_weights, reduction=\"none\")\n\nagent = Agent(in_features, not randt, not randm)\nstate = {}\nbest_score = 0","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def _register_head_hook(model):\n    def hook(module, input, output):\n        state['head_input'] = input[0].detach()\n        \n    _hook_handle = model.classifier[-1].register_forward_hook(hook)\n    return _hook_handle\n    \ndef _remove_head_hook(_hook_handle):\n    _hook_handle.remove()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"epochs = 5\nr_weight = 1\nmodel.to(device)\n\n\n#### use forward hook here\n\nif torch.cuda.device_count() > 1:\n    print(f\"Using {torch.cuda.device_count()} GPUs\")\n    model = nn.DataParallel(model)\n    \nfor epoch in range(epochs):\n    # Training\n    \n    model.train()\n    handle = _register_head_hook()\n    \n    train_loss, total_actor_loss, total_critic_loss = 0, 0, 0\n    for keys, imgs, targets in tqdm(train_loader, desc=\"Training\"):\n        imgs, targets = imgs.to(device, non_blocking=True), targets.to(device, non_blocking=True)\n\n        logits = model(imgs)\n        state = state[\"head_input\"]\n\n        loss = bce_loss(logits, targets)\n        prev_loss = agent.loss_memory(keys, loss.detach())\n        probs = torch.sigmoid(logits)\n\n        action, transform_idx = agent.action(state)\n        ada_augment.set(keys, action, transform_idx)\n\n        entropy = -torch.sum(probs * torch.log(probs + 1e-8), dim=1).unsqueeze(1)\n        reward = r_weight = (loss.detach().mean() - prev_loss.mean()) + (1 - r_weight) * entropy\n\n        actor_loss, critic_loss = agent.update(keys, state, reward)\n\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        train_loss += loss.item()\n        total_actor_loss += actor_loss.item()\n        total_critic_loss += critic_loss.item()\n    train_loss /= len(train_loader)\n    total_actor_loss /= len(train_loader)\n    total_critic_loss /= len(train_loader)\n\n    _remove_head_hook(handle)\n    # Validation\n    model.eval()\n    val_loss = 0\n\n    all_probs = []\n    all_targets = []\n\n    with torch.inference_mode():\n        for keys, imgs, targets in tqdm(val_loader, desc=\"Validation\"):\n            imgs, targets = imgs.to(device, non_blocking=True), targets.to(device, non_blocking=True)\n\n            logits = model(imgs)\n            loss = bce_loss(logits, targets)\n            probs = torch.sigmoid(logits)\n\n            val_loss += loss.item()\n\n            all_probs.append(probs)\n            all_targets.append(targets)\n\n    val_loss /= len(val_loader)\n    all_probs = torch.cat(all_probs, dim=0)\n    all_targets = torch.cat(all_targets, dim=0)\n\n    val_accuracy  = accuracy(all_probs, all_targets.int(), task=\"multilabel\", num_labels=14)\n    val_precision = precision(all_probs, all_targets.int(), task=\"multilabel\", num_labels=14)\n    val_recall = recall(all_probs, all_targets.int(), task=\"multilabel\", num_labels=14)\n    val_auroc = auroc(all_probs, all_targets.int(), task=\"multilabel\", num_labels=14)\n\n    if val_auroc > best_score:\n        best_score = val_auroc\n        initial_best_model = model.module.state_dict() if torch.cuda.device_count() > 1 else model.state_dict()\n        torch.save(initial_best_model, \"best_model.pth\")\n        print(f\"New best auroc score: {best_score:.4f}\")\n\n    print(\n        f\"Epoch {epoch+1}/{epochs} | \"\n        f\"Train Loss: {train_loss:.4f} | \"\n        f\"Actor Loss: {total_actor_loss:.4f} |\"\n        f\"Critic LOss: {total_critic_loss:.4f} |\"\n        f\"Val Loss: {val_loss:.4f} | \"\n        f\"Acc: {val_accuracy:.4f} | \"\n        f\"Prec: {val_precision:.4f} | \"\n        f\"Rec: {val_recall:.4f} | \"\n        f\"AUROC: {val_auroc:.4f}\"\n    )","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Create submission using the best model","metadata":{}},{"cell_type":"code","source":"def create_submission(model_name=model_name):\n    get_model, _ = models_[model_name]\n    model = get_model()\n    model.load_state_dict(torch.load(\"best_model.pth\", map_location=device, weights_only=False))\n\n    model.eval()\n    \n    all_keys = []\n    all_probs = []\n    \n    with torch.inference_mode():\n        for key, img in tqdm(test_loader):\n            img = img.to(device)\n\n            out = model(img)\n            probs = torch.sigmoid(out)\n\n            all_keys.extend(key)\n            all_probs.append(probs.cpu().numpy())\n            \n    all_probs = np.concat(all_probs, axis=0)\n\n    return all_keys, all_probs","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"all_keys, all_probs = create_submission()\n\nthreshold = 0.5\n\nfinal_submission_= pd.DataFrame()\nfinal_submission[\"Image_name\"] = all_keys\nfinal_submission[label_columns] = np.int(all_probs > threshold.astype(int)\nfinal_submission.to_csv('/kaggle/working/submission.csv', index=False)\n\nprint(\"=\"* 60)\nprint(\"Final submission file created at /kaggle/working/submission.csv\")\nprint(\"=\"* 60)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}